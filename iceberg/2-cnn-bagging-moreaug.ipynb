{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "\n",
    "* Add FFT channels to CNN (Tried, does not make much difference)\n",
    "* Finetune CNN (with SGD slow learning rate)\n",
    "* 5-fold CNN\n",
    "* Extract Features from CNN (before FC) and do XGB\n",
    "* TTA (tried, made it better)\n",
    "* More augmenting, additional 45, 135, 315 degrees\n",
    "* More augmenting, random rotations and flips\n",
    "* Predict test data and train with test\n",
    "* Train on all of the training data (no train-val split)\n",
    "* Try a different combination of combine predictions\n",
    "* Fine-tune on pre-trained models (Get rid of some top layers because input size is small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/can/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import transform\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras import losses, optimizers, callbacks\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate, train_test_split, StratifiedKFold, KFold\n",
    "from scipy import fftpack\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "RANDOM_SEED = 43\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (1604, 75, 75, 2)\n",
      "y.shape: (1604,)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "df = pd.read_json('./data/train.json')\n",
    "X, y = [], []\n",
    "for im_band1, im_band2, label in zip(df['band_1'], df['band_2'], df['is_iceberg']):\n",
    "    im_band1 = np.array(im_band1).reshape(75, 75, 1)\n",
    "    im_band2 = np.array(im_band2).reshape(75, 75, 1)    \n",
    "    # Preprocess\n",
    "    # - Zero mean\n",
    "    im_band1 -= np.mean(im_band1)\n",
    "    im_band2 -= np.mean(im_band2)\n",
    "    # - Normalize\n",
    "    im_band1 /= np.std(im_band1)\n",
    "    im_band2 /= np.std(im_band2)    \n",
    "    im = np.concatenate([im_band1, im_band2], axis=2)\n",
    "    X.append(im)\n",
    "    y.append(label)    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print 'X.shape:', X.shape\n",
    "print 'y.shape:', y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "MODEL_NUMBER = 5\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, random_state=RANDOM_SEED, shuffle=True)\n",
    "cv = list(skf.split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1284, 75, 75, 2)\n",
      "y_train.shape: (1284,)\n",
      "X_val.shape: (320, 75, 75, 2)\n",
      "y_val.shape: (320,)\n",
      "np.mean(y_train): 0.469626168224\n",
      "np.mean(y_val): 0.46875\n"
     ]
    }
   ],
   "source": [
    "train_i, val_i = cv[MODEL_NUMBER - 1]\n",
    "X_train, y_train = X[train_i], y[train_i]\n",
    "X_val, y_val = X[val_i], y[val_i]\n",
    "print 'X_train.shape:', X_train.shape\n",
    "print 'y_train.shape:', y_train.shape\n",
    "print 'X_val.shape:', X_val.shape\n",
    "print 'y_val.shape:', y_val.shape\n",
    "print 'np.mean(y_train):', np.mean(y_train)\n",
    "print 'np.mean(y_val):', np.mean(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bypass(im):\n",
    "    return im\n",
    "\n",
    "def h_flip(im):\n",
    "    return im[:, ::-1]\n",
    "\n",
    "def v_flip(x):\n",
    "    return im[::-1, :]\n",
    "\n",
    "def hv_flip(x):\n",
    "    return h_flip(v_flip(x))\n",
    "\n",
    "def random_rot(im):\n",
    "    angle = int((np.random.randint(3) + 1) * 90)\n",
    "    return transform.rotate(im, angle=angle, mode='reflect')\n",
    "\n",
    "aug_funcs = [h_flip, v_flip, random_rot]             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(X, y, aug_funcs, batch_size=32, augment=True):\n",
    "    \"\"\"\n",
    "    Generates random data\n",
    "    \"\"\"\n",
    "    X = list(np.copy(X))\n",
    "    y = list(np.copy(y))\n",
    "    X_y = zip(X, y)\n",
    "    while True:\n",
    "        X_y_batch = random.sample(X_y, batch_size)\n",
    "        X_batch = [e[0] for e in X_y_batch]\n",
    "        y_batch = [e[1] for e in X_y_batch]\n",
    "        # Random augmentation        \n",
    "        for i, x in enumerate(X_batch):            \n",
    "            funcs2apply = random.sample(aug_funcs, np.random.randint(len(aug_funcs) + 1))\n",
    "            for f in funcs2apply:\n",
    "                x = f(x)\n",
    "            X_batch[i] = x\n",
    "        yield np.array(X_batch), np.array(y_batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[  1.64646565e+00,  -1.60878319e+00],\n",
       "          [  1.09838933e+00,  -9.45093800e-01],\n",
       "          [  1.26320902e+00,  -1.15458792e+00],\n",
       "          ..., \n",
       "          [  2.51328846e-01,  -1.37666199e+00],\n",
       "          [  7.44300160e-01,  -7.47149017e-01],\n",
       "          [  1.57160931e+00,  -5.57186834e-01]],\n",
       " \n",
       "         [[  1.18172089e+00,  -2.00497486e-01],\n",
       "          [  1.34303309e+00,   8.44682883e-01],\n",
       "          [  9.26038842e-01,   8.44664076e-01],\n",
       "          ..., \n",
       "          [  7.44317180e-01,  -7.47131151e-01],\n",
       "          [ -1.28567083e+00,  -1.61010954e+00],\n",
       "          [  5.54709908e-01,  -7.47167824e-01]],\n",
       " \n",
       "         [[  1.42121101e+00,   8.44700750e-01],\n",
       "          [  8.36859743e-01,   1.45535178e+00],\n",
       "          [  1.18168641e+00,   1.22190516e+00],\n",
       "          ..., \n",
       "          [  2.51312262e-01,  -5.57168027e-01],\n",
       "          [  2.51294806e-01,  -7.47167824e-01],\n",
       "          [  6.50663938e-01,   1.25022673e-01]],\n",
       " \n",
       "         ..., \n",
       "         [[ -1.28461034e+00,  -9.45260241e-01],\n",
       "          [ -1.79079983e+00,  -7.46025303e-01],\n",
       "          [ -1.12990242e+00,  -9.45297385e-01],\n",
       "          ..., \n",
       "          [ -3.32898089e+00,  -2.01990756e-01],\n",
       "          [ -1.28584234e+00,  -9.46587540e-01],\n",
       "          [ -7.87076651e-02,  -3.77732996e+00]],\n",
       " \n",
       "         [[ -4.38746940e-01,   1.56707950e+00],\n",
       "          [ -1.79079983e+00,  -7.46025303e-01],\n",
       "          [ -2.82162747e+00,  -9.45297385e-01],\n",
       "          ..., \n",
       "          [  3.55000903e-01,   4.27522213e-01],\n",
       "          [  3.44551417e-02,  -7.47352602e-01],\n",
       "          [ -1.95369223e-01,  -1.85791431e+00]],\n",
       " \n",
       "         [[ -1.28461034e+00,   1.56707950e+00],\n",
       "          [ -1.61445788e+00,   1.88544598e+00],\n",
       "          [ -1.61447577e+00,   9.74138482e-01],\n",
       "          ..., \n",
       "          [  7.44128649e-01,   1.33881184e+00],\n",
       "          [  3.54984319e-01,   1.24856702e-01],\n",
       "          [ -7.01542574e-01,  -1.15609999e+00]]],\n",
       " \n",
       " \n",
       "        [[[ -3.96464273e-01,  -1.21633130e+00],\n",
       "          [  8.19579793e-01,  -1.63864351e+00],\n",
       "          [  2.02378907e+00,  -1.02081228e+00],\n",
       "          ..., \n",
       "          [ -8.10587531e-01,  -1.66013873e-01],\n",
       "          [ -5.30367129e-01,  -6.57432003e-01],\n",
       "          [ -5.30383673e-01,   7.89522225e-01]],\n",
       " \n",
       "         [[  4.21178645e-01,   7.90817047e-01],\n",
       "          [  1.00407961e+00,   1.24936627e+00],\n",
       "          [  9.12937688e-01,   1.56182349e+00],\n",
       "          ..., \n",
       "          [ -1.61821372e+00,  -1.47476677e-02],\n",
       "          [ -2.54210696e-02,  -1.21761044e+00],\n",
       "          [  9.11749594e-01,  -8.35616753e-01]],\n",
       " \n",
       "         [[  1.26499098e+00,   1.75741451e+00],\n",
       "          [  1.26497443e+00,   2.29260232e+00],\n",
       "          [  1.00406306e+00,   2.53557293e+00],\n",
       "          ..., \n",
       "          [ -1.61821372e+00,  -1.47476677e-02],\n",
       "          [ -1.11328376e+00,  -3.23230907e-01],\n",
       "          [  4.19956593e-01,  -3.23249365e-01]],\n",
       " \n",
       "         ..., \n",
       "         [[  8.19362984e-01,   2.72677411e-01],\n",
       "          [ -8.09650204e-01,  -4.85837186e-01],\n",
       "          [ -9.57978672e-01,   6.67197550e-01],\n",
       "          ..., \n",
       "          [  3.13227525e-01,  -3.23462553e-01],\n",
       "          [  7.22418603e-01,  -1.21785869e+00],\n",
       "          [ -9.59168507e-01,   9.08925476e-01]],\n",
       " \n",
       "         [[ -3.96698496e-01,   1.02640587e+00],\n",
       "          [ -1.11232902e+00,   5.39964457e-01],\n",
       "          [ -5.29428931e-01,   1.85144275e+00],\n",
       "          ..., \n",
       "          [  2.03611592e-01,  -1.49963880e-02],\n",
       "          [ -3.97904875e-01,   2.71398740e-01],\n",
       "          [ -2.69723069e-01,   9.08925476e-01]],\n",
       " \n",
       "         [[ -8.09633225e-01,  -3.22201879e-01],\n",
       "          [ -2.68516689e-01,  -3.22219414e-01],\n",
       "          [  9.12704336e-01,   6.67197550e-01],\n",
       "          ..., \n",
       "          [ -2.56383136e-02,  -1.64013352e+00],\n",
       "          [ -6.68125087e-01,  -1.66281513e-01],\n",
       "          [  1.26353383e+00,   5.38685324e-01]]],\n",
       " \n",
       " \n",
       "        [[[  8.30355443e-01,   1.40873058e+00],\n",
       "          [  6.39145441e-01,   7.08308913e-01],\n",
       "          [ -1.19763160e-01,  -1.33053870e-01],\n",
       "          ..., \n",
       "          [ -1.75477737e+00,   1.64881348e-01],\n",
       "          [ -2.82709318e+00,  -6.28564795e-01],\n",
       "          [ -1.23387775e+00,  -1.18843826e+00]],\n",
       " \n",
       "         [[  1.18563224e+00,   1.66619532e-01],\n",
       "          [  7.35986760e-01,   1.66595397e-01],\n",
       "          [ -6.34677726e-01,  -4.55699204e-01],\n",
       "          ..., \n",
       "          [ -1.57291892e+00,  -1.34720615e-01],\n",
       "          [ -2.14751576e+00,   1.77318094e-02],\n",
       "          [ -1.39956537e+00,   1.64832596e-01]],\n",
       " \n",
       "         [[  2.24610355e-01,  -2.91212713e-01],\n",
       "          [  4.37638083e-01,  -6.26826611e-01],\n",
       "          [ -7.75349322e-01,  -1.18669911e+00],\n",
       "          ..., \n",
       "          [ -1.94596506e+00,   1.77559442e-02],\n",
       "          [ -1.23385587e+00,   3.06993482e-01],\n",
       "          [ -7.76894612e-01,   4.44445680e-01]],\n",
       " \n",
       "         ..., \n",
       "         [[  4.37964650e-01,   5.79685205e-01],\n",
       "          [ -4.98796486e-01,   1.40907233e+00],\n",
       "          [  1.13598800e-01,   1.30014257e+00],\n",
       "          ..., \n",
       "          [ -2.43158062e-01,  -1.34375971e-01],\n",
       "          [ -7.76567187e-01,   1.80754882e-02],\n",
       "          [ -3.08397006e+00,   1.65175792e-01]],\n",
       " \n",
       "         [[ -4.98774600e-01,   1.71980379e+00],\n",
       "          [ -3.67998267e-01,   1.81843428e+00],\n",
       "          [  1.13598800e-01,   1.51519666e+00],\n",
       "          ..., \n",
       "          [  1.12097710e-01,  -9.93004267e-01],\n",
       "          [ -2.43179948e-01,  -4.57070057e-01],\n",
       "          [ -1.75451517e+00,   4.44788393e-01]],\n",
       " \n",
       "         [[ -2.41613201e-01,   2.36610232e+00],\n",
       "          [ -4.98796486e-01,   1.07348353e+00],\n",
       "          [ -9.21234823e-01,   7.08651626e-01],\n",
       "          ..., \n",
       "          [  2.23391631e-01,  -4.57022270e-01],\n",
       "          [ -2.60005482e-03,  -8.06634803e-01],\n",
       "          [ -3.69542699e-01,  -1.39262930e+00]]],\n",
       " \n",
       " \n",
       "        ..., \n",
       "        [[[  6.90728523e-02,   5.40044840e-01],\n",
       "          [ -3.93937880e-01,   4.57945222e-01],\n",
       "          [ -3.31297915e-01,   5.39997437e-01],\n",
       "          ..., \n",
       "          [  3.97862999e-01,   5.78345153e-01],\n",
       "          [  5.04150445e-01,   3.71236031e-01],\n",
       "          [ -2.92185275e-01,  -2.88415668e-03]],\n",
       " \n",
       "         [[  9.17379847e-01,   5.80045349e-01],\n",
       "          [  1.21446235e-01,  -2.68854048e-01],\n",
       "          [  3.52689273e-01,   9.79954377e-02],\n",
       "          ..., \n",
       "          [  3.66658789e-01,   2.83103388e-01],\n",
       "          [  7.04376629e-01,  -3.86673955e-01],\n",
       "          [  3.19075358e-01,  -3.86697519e-01]],\n",
       " \n",
       "         [[  8.00759243e-01,   6.19385235e-01],\n",
       "          [ -1.90757598e-01,   3.72936776e-01],\n",
       "          [  3.34831548e-02,   4.89229217e-02],\n",
       "          ..., \n",
       "          [  9.28161953e-01,   4.72462897e-02],\n",
       "          [  3.19075358e-01,  -7.73488211e-01],\n",
       "          [ -2.32002738e-01,  -1.23559746e+00]],\n",
       " \n",
       "         ..., \n",
       "         [[ -3.52248210e-01,  -1.04893197e-01],\n",
       "          [ -6.38094346e-01,  -3.26469468e-01],\n",
       "          [ -8.81993639e-01,  -4.45515818e-01],\n",
       "          ..., \n",
       "          [ -3.12805636e-01,  -3.86913982e-01],\n",
       "          [ -1.73410666e-01,  -3.28169664e-01],\n",
       "          [ -8.83822128e-01,  -3.14802277e-03]],\n",
       " \n",
       "         [[  7.19667358e-01,  -5.25838684e-02],\n",
       "          [  3.52431512e-01,  -2.13116105e-01],\n",
       "          [ -3.73187312e-01,  -5.70806724e-01],\n",
       "          ..., \n",
       "          [ -5.93792886e-01,  -5.08990545e-01],\n",
       "          [ -8.58335812e-01,  -6.37692256e-01],\n",
       "          [ -4.38721869e-01,  -2.70842771e-01]],\n",
       " \n",
       "         [[  1.14711402e+00,   2.39206265e-01],\n",
       "          [  3.36588436e-01,   9.77565060e-02],\n",
       "          [ -5.46727041e-01,  -2.13139669e-01],\n",
       "          ..., \n",
       "          [ -8.08137350e-01,  -2.15866022e+00],\n",
       "          [ -1.55255865e+00,  -1.07161305e+00],\n",
       "          [ -6.39949053e-01,  -1.60125876e-01]]],\n",
       " \n",
       " \n",
       "        [[[ -3.27693985e-01,   1.07927083e+00],\n",
       "          [  6.81232184e-02,   5.82569108e-01],\n",
       "          [ -2.89492341e-01,  -4.52294603e-01],\n",
       "          ..., \n",
       "          [  1.24579277e+00,  -7.52864734e-01],\n",
       "          [  1.64726140e+00,  -9.65730560e-02],\n",
       "          [  1.15381606e+00,   1.46360650e-01]],\n",
       " \n",
       "         [[  3.42440149e-02,   3.00005249e-01],\n",
       "          [  1.34717143e-01,  -1.16130582e-02],\n",
       "          [  1.34717143e-01,  -1.16130582e-02],\n",
       "          ..., \n",
       "          [  1.01039838e+00,  -8.59379770e-01],\n",
       "          [  1.94771186e+00,   1.46386161e-01],\n",
       "          [  1.48476286e+00,   8.39210379e-01]],\n",
       " \n",
       "         [[  5.91707558e-01,  -9.47541171e-02],\n",
       "          [  3.26035259e-01,   1.48180288e-01],\n",
       "          [  6.47592135e-01,   5.82519135e-01],\n",
       "          ..., \n",
       "          [  8.85299449e-01,   2.23260355e-01],\n",
       "          [  2.07015316e+00,   3.71331417e-01],\n",
       "          [  1.70593978e+00,   7.12718118e-01]],\n",
       " \n",
       "         ..., \n",
       "         [[ -2.51950410e-01,  -1.73106037e+00],\n",
       "          [ -5.27018430e-01,  -6.48445061e-01],\n",
       "          [ -2.89764008e-01,  -9.50560505e-02],\n",
       "          ..., \n",
       "          [ -1.07282921e-01,  -9.70022975e-01],\n",
       "          [ -4.07757955e-01,  -9.68264144e-02],\n",
       "          [  3.85135473e-01,   7.76369447e-01]],\n",
       " \n",
       "         [[ -3.27964629e-01,  -4.52521053e-01],\n",
       "          [ -5.27018430e-01,  -6.48445061e-01],\n",
       "          [  2.63353886e-01,   2.24751500e-01],\n",
       "          ..., \n",
       "          [  2.29945322e-01,  -1.36353828e-02],\n",
       "          [ -1.11907072e+00,  -1.36598450e-02],\n",
       "          [ -8.77953232e-01,   4.42476565e-01]],\n",
       " \n",
       "         [[ -1.85512225e+00,  -1.32574312e+00],\n",
       "          [ -4.45796122e-01,  -9.50312388e-02],\n",
       "          [ -3.49952506e-02,   6.48980821e-01],\n",
       "          ..., \n",
       "          [  4.45049323e-01,   1.13390993e+00],\n",
       "          [  9.95710699e-02,   1.07714716e+00],\n",
       "          [  3.85110559e-01,   5.80446139e-01]]],\n",
       " \n",
       " \n",
       "        [[[ -4.81752145e-01,   8.45305202e-01],\n",
       "          [  6.42880575e-02,  -6.11193326e-01],\n",
       "          [ -8.54184668e-01,  -3.02198231e-01],\n",
       "          ..., \n",
       "          [  7.53431758e-01,   1.36048873e+00],\n",
       "          [  1.82977411e+00,  -6.11516880e-01],\n",
       "          [  1.70355162e+00,  -3.02520896e-01]],\n",
       " \n",
       "         [[ -3.09088235e-01,   1.19327484e-01],\n",
       "          [ -3.65733888e-01,  -7.75514386e-01],\n",
       "          [  7.95269873e-01,  -6.11217770e-01],\n",
       "          ..., \n",
       "          [  1.86064934e+00,   1.26272782e+00],\n",
       "          [  1.76719335e+00,  -1.51338361e+00],\n",
       "          [  1.50548047e+00,   3.76457916e-01]],\n",
       " \n",
       "         [[ -2.53343699e-01,   1.19303039e-01],\n",
       "          [ -1.44335594e-01,   3.76756582e-01],\n",
       "          [  1.83002837e+00,   1.19303039e-01],\n",
       "          ..., \n",
       "          [  1.89123841e+00,   2.49876691e-01],\n",
       "          [  1.89123841e+00,   2.49876691e-01],\n",
       "          [  4.93227090e-01,  -7.75862829e-01]],\n",
       " \n",
       "         ..., \n",
       "         [[ -3.10710741e-01,  -1.94417506e+00],\n",
       "          [ -1.19865734e+00,  -2.17820826e+00],\n",
       "          [  1.11006784e+00,  -6.12959985e-01],\n",
       "          ..., \n",
       "          [  9.55057681e-01,   8.43240322e-01],\n",
       "          [  9.55057681e-01,   7.31337700e-01],\n",
       "          [ -7.27654911e-01,  -7.77579266e-01]],\n",
       " \n",
       "         [[ -1.12745138e+00,  -9.48882073e-01],\n",
       "          [ -2.38029814e+00,  -4.55396673e-01],\n",
       "          [  5.36589151e-01,   2.48434031e-01],\n",
       "          ..., \n",
       "          [  8.34454334e-01,  -1.82034712e-02],\n",
       "          [  8.34454334e-01,  -1.82034712e-02],\n",
       "          [  1.10974317e+00,  -9.49205183e-01]],\n",
       " \n",
       "         [[ -1.49862457e+00,  -1.94422395e+00],\n",
       "          [ -2.18584263e+00,  -2.17825804e+00],\n",
       "          [ -7.27399815e-01,  -1.79288058e-02],\n",
       "          ..., \n",
       "          [ -8.56154617e-01,   7.31287922e-01],\n",
       "          [  7.09667590e-01,   8.43190100e-01],\n",
       "          [  6.67077441e-01,  -4.55744227e-01]]]]),\n",
       " array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gen_obj = data_generator(X_train, y_train, batch_size=32, aug_funcs=aug_funcs)\n",
    "next(gen_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_shape):\n",
    "    # Architecture\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    loss = losses.binary_crossentropy\n",
    "    optimizer = optimizers.Adam()\n",
    "    metrics = ['accuracy']\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    #     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model(input_shape=(75, 75, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.6489 - acc: 0.5748Epoch 00000: val_loss improved from inf to 0.60458, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 6s - loss: 0.6487 - acc: 0.5755 - val_loss: 0.6046 - val_acc: 0.6219\n",
      "Epoch 2/200\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.5597 - acc: 0.6591Epoch 00001: val_loss improved from 0.60458 to 0.32088, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 5s - loss: 0.5593 - acc: 0.6594 - val_loss: 0.3209 - val_acc: 0.8656\n",
      "Epoch 3/200\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.5005 - acc: 0.6851Epoch 00002: val_loss improved from 0.32088 to 0.31882, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 5s - loss: 0.5003 - acc: 0.6842 - val_loss: 0.3188 - val_acc: 0.8531\n",
      "Epoch 4/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.4891 - acc: 0.6966Epoch 00003: val_loss improved from 0.31882 to 0.27398, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 5s - loss: 0.4891 - acc: 0.6964 - val_loss: 0.2740 - val_acc: 0.8906\n",
      "Epoch 5/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.4632 - acc: 0.7087Epoch 00004: val_loss improved from 0.27398 to 0.25520, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 5s - loss: 0.4636 - acc: 0.7087 - val_loss: 0.2552 - val_acc: 0.8906\n",
      "Epoch 6/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.4487 - acc: 0.7174Epoch 00005: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.4488 - acc: 0.7175 - val_loss: 0.2680 - val_acc: 0.8969\n",
      "Epoch 7/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.4382 - acc: 0.7268Epoch 00006: val_loss improved from 0.25520 to 0.25229, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 5s - loss: 0.4390 - acc: 0.7262 - val_loss: 0.2523 - val_acc: 0.8875\n",
      "Epoch 8/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.4444 - acc: 0.7246Epoch 00007: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.4441 - acc: 0.7252 - val_loss: 0.3016 - val_acc: 0.8844\n",
      "Epoch 9/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.4368 - acc: 0.7266Epoch 00008: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.4363 - acc: 0.7269 - val_loss: 0.2935 - val_acc: 0.8938\n",
      "Epoch 10/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.4333 - acc: 0.7295Epoch 00009: val_loss improved from 0.25229 to 0.24857, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 5s - loss: 0.4336 - acc: 0.7289 - val_loss: 0.2486 - val_acc: 0.9031\n",
      "Epoch 11/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.4265 - acc: 0.7337Epoch 00010: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.4266 - acc: 0.7335 - val_loss: 0.2555 - val_acc: 0.9000\n",
      "Epoch 12/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.4204 - acc: 0.7329Epoch 00011: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.4202 - acc: 0.7331 - val_loss: 0.2597 - val_acc: 0.9219\n",
      "Epoch 13/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.4181 - acc: 0.7365Epoch 00012: val_loss did not improve\n",
      "\n",
      "Epoch 00012: reducing learning rate to 0.000500000023749.\n",
      "320/320 [==============================] - 5s - loss: 0.4179 - acc: 0.7367 - val_loss: 0.2692 - val_acc: 0.9125\n",
      "Epoch 14/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.4030 - acc: 0.7454Epoch 00013: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.4026 - acc: 0.7456 - val_loss: 0.3074 - val_acc: 0.9125\n",
      "Epoch 15/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.3916 - acc: 0.7518Epoch 00014: val_loss did not improve\n",
      "\n",
      "Epoch 00014: reducing learning rate to 0.000250000011874.\n",
      "320/320 [==============================] - 5s - loss: 0.3920 - acc: 0.7516 - val_loss: 0.3140 - val_acc: 0.9094\n",
      "Epoch 16/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.3937 - acc: 0.7465Epoch 00015: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.3934 - acc: 0.7466 - val_loss: 0.3094 - val_acc: 0.9187\n",
      "Epoch 17/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.3804 - acc: 0.7546Epoch 00016: val_loss did not improve\n",
      "\n",
      "Epoch 00016: reducing learning rate to 0.000125000005937.\n",
      "320/320 [==============================] - 5s - loss: 0.3803 - acc: 0.7547 - val_loss: 0.3068 - val_acc: 0.9125\n",
      "Epoch 18/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.3884 - acc: 0.7496Epoch 00017: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.3886 - acc: 0.7496 - val_loss: 0.3524 - val_acc: 0.9031\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f58cd0be250>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callbacks\n",
    "def get_lr(epoch):\n",
    "    lr = (np.random.rand() * 1e-3 + 1e-7)\n",
    "    print 'lr:', lr\n",
    "    return lr\n",
    "MODEL_PATH = './models/model6/model' + str(MODEL_NUMBER) + '.h5'\n",
    "m_q = 'val_loss'\n",
    "model_path = MODEL_PATH\n",
    "check_pt = callbacks.ModelCheckpoint(filepath=model_path, monitor=m_q, save_best_only=True, verbose=1)\n",
    "early_stop = callbacks.EarlyStopping(patience=7, monitor=m_q, verbose=1)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(patience=2, factor=0.5, monitor=m_q, verbose=1)\n",
    "schedule_lr = callbacks.LearningRateScheduler(get_lr)\n",
    "callback_list = [check_pt, early_stop, reduce_lr]\n",
    "\n",
    "# Fit generator\n",
    "batch_size = 32\n",
    "steps_per_epoch = (len(X_train) / batch_size) * 8\n",
    "gen_obj = data_generator(X_train, y_train, batch_size=batch_size, aug_funcs=aug_funcs)\n",
    "model.fit_generator(gen_obj, steps_per_epoch=steps_per_epoch, validation_data=(X_val, y_val), callbacks=callback_list, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Finetune\n",
    "# loss = losses.binary_crossentropy\n",
    "# optimizer = optimizers.SGD(lr=1e-4)\n",
    "# metrics = ['accuracy']\n",
    "# model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# m_q = 'val_loss'\n",
    "# model_path = MODEL_PATH\n",
    "# check_pt = callbacks.ModelCheckpoint(filepath=model_path, monitor=m_q, save_best_only=True, verbose=1)\n",
    "# early_stop = callbacks.EarlyStopping(patience=5, monitor=m_q, verbose=1)\n",
    "# reduce_lr = callbacks.ReduceLROnPlateau(patience=2, factor=0.33, monitor=m_q, verbose=1)\n",
    "# callback_list = [check_pt, early_stop, reduce_lr]\n",
    "\n",
    "# model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=callback_list, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape: (8424, 75, 75, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "df = pd.read_json('./data/test.json')\n",
    "X_test, y_test = [], []\n",
    "for im_band1, im_band2 in zip(df['band_1'], df['band_2']):\n",
    "    im_band1 = np.array(im_band1).reshape(75, 75, 1)\n",
    "    im_band2 = np.array(im_band2).reshape(75, 75, 1)    \n",
    "    # Preprocess - zero mean\n",
    "    im_band1 -= np.mean(im_band1)\n",
    "    im_band2 -= np.mean(im_band2)\n",
    "    # Preprocess - normalize\n",
    "    im_band1 /= np.std(im_band1)\n",
    "    im_band2 /= np.std(im_band2)    \n",
    "    im = np.concatenate([im_band1, im_band2], axis=2)\n",
    "    X_test.append(im)    \n",
    "X_test = np.array(X_test)\n",
    "print 'X_test.shape:', X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict - tta\n",
    "def bypass(x):\n",
    "    return x\n",
    "\n",
    "def h_flip(x):\n",
    "    return x[:, :, ::-1, :]\n",
    "\n",
    "def v_flip(x):\n",
    "    return x[:, ::-1, :, :]\n",
    "\n",
    "def hv_flip(x):\n",
    "    return h_flip(v_flip(x))\n",
    "\n",
    "def rot90(x):\n",
    "    return np.concatenate([np.expand_dims(transform.rotate(im, 90), axis=0) for im in x], axis=0)\n",
    "\n",
    "def rot180(x):\n",
    "    return np.concatenate([np.expand_dims(transform.rotate(im, 180), axis=0) for im in x], axis=0)\n",
    "\n",
    "def rot270(x):\n",
    "    return np.concatenate([np.expand_dims(transform.rotate(im, 270), axis=0) for im in x], axis=0)\n",
    "\n",
    "tta_aug_funcs = [bypass, \n",
    "                 h_flip, v_flip, hv_flip,\n",
    "                 rot90, rot180, rot270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "8424/8424 [==============================] - 1s     \n",
      "8424/8424 [==============================] - 1s     \n",
      "8288/8424 [============================>.] - ETA: 0s1\n",
      "8416/8424 [============================>.] - ETA: 0s2\n",
      "8352/8424 [============================>.] - ETA: 0s3\n",
      "8424/8424 [==============================] - 1s     \n",
      "8424/8424 [==============================] - 1s     \n",
      "4\n",
      "8424/8424 [==============================] - 1s     \n",
      "8384/8424 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_test_p = 0\n",
    "weights = [0.25, 0.5 / 3, 0.25, 0.5 / 3, 0.5 / 3]\n",
    "for i, w in zip(range(5), weights):\n",
    "    print i\n",
    "    # Load the model\n",
    "    MODEL_PATH = './models/model6/model' + str(i + 1) + '.h5'\n",
    "    model = load_model(MODEL_PATH)\n",
    "    # predict - tta    \n",
    "    for func in tta_aug_funcs:\n",
    "        y_test_p += model.predict(func(X_test), verbose=1).flatten() * w\n",
    "# y_test_p = y_test_p / (len(aug_funcs) * 5.0)\n",
    "y_test_p = y_test_p / (len(tta_aug_funcs) * sum(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame()\n",
    "df_sub['id'] = df['id']\n",
    "df_sub['is_iceberg'] = y_test_p.flatten()\n",
    "df_sub.to_csv('./submissions/sub16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
