{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "\n",
    "* Add FFT channels to CNN (Tried, does not make much difference)\n",
    "* Finetune CNN (with SGD slow learning rate)\n",
    "* 5-fold CNN\n",
    "* Extract Features from CNN (before FC) and do XGB\n",
    "* TTA (tried, made it better)\n",
    "* More augmenting, additional 45, 135, 315 degrees\n",
    "* More augmenting, random rotations and flips\n",
    "* Predict test data and train with test\n",
    "* Train on all of the training data (no train-val split)\n",
    "* Try a different combination of combine predictions\n",
    "* Fine-tune on pre-trained models (Get rid of some top layers because input size is small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/can/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import transform\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras import losses, optimizers, callbacks\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate, train_test_split, StratifiedKFold, KFold\n",
    "from scipy import fftpack\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "RANDOM_SEED = 43\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (1604, 75, 75, 2)\n",
      "y.shape: (1604,)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "df = pd.read_json('./data/train.json')\n",
    "X, y = [], []\n",
    "for im_band1, im_band2, label in zip(df['band_1'], df['band_2'], df['is_iceberg']):\n",
    "    im_band1 = np.array(im_band1).reshape(75, 75, 1)\n",
    "    im_band2 = np.array(im_band2).reshape(75, 75, 1)    \n",
    "    # Preprocess\n",
    "    # - Zero mean\n",
    "    im_band1 -= np.mean(im_band1)\n",
    "    im_band2 -= np.mean(im_band2)\n",
    "    # - Normalize\n",
    "    im_band1 /= np.std(im_band1)\n",
    "    im_band2 /= np.std(im_band2)    \n",
    "    im = np.concatenate([im_band1, im_band2], axis=2)\n",
    "    X.append(im)\n",
    "    y.append(label)    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print 'X.shape:', X.shape\n",
    "print 'y.shape:', y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "MODEL_NUMBER = 5\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, random_state=RANDOM_SEED, shuffle=True)\n",
    "cv = list(skf.split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1284, 75, 75, 2)\n",
      "y_train.shape: (1284,)\n",
      "X_val.shape: (320, 75, 75, 2)\n",
      "y_val.shape: (320,)\n",
      "np.mean(y_train): 0.469626168224\n",
      "np.mean(y_val): 0.46875\n"
     ]
    }
   ],
   "source": [
    "train_i, val_i = cv[MODEL_NUMBER - 1]\n",
    "X_train, y_train = X[train_i], y[train_i]\n",
    "X_val, y_val = X[val_i], y[val_i]\n",
    "print 'X_train.shape:', X_train.shape\n",
    "print 'y_train.shape:', y_train.shape\n",
    "print 'X_val.shape:', X_val.shape\n",
    "print 'y_val.shape:', y_val.shape\n",
    "print 'np.mean(y_train):', np.mean(y_train)\n",
    "print 'np.mean(y_val):', np.mean(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bypass(im):\n",
    "    return im\n",
    "\n",
    "def h_flip(im):\n",
    "    return im[:, ::-1]\n",
    "\n",
    "def v_flip(x):\n",
    "    return im[::-1, :]\n",
    "\n",
    "def hv_flip(x):\n",
    "    return h_flip(v_flip(x))\n",
    "\n",
    "def random_rot(im):\n",
    "    angle = int((np.random.randint(3) + 1) * 90)\n",
    "    return transform.rotate(im, angle=angle, mode='reflect')\n",
    "\n",
    "aug_funcs = [h_flip, v_flip, random_rot]             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(X, y, aug_funcs, batch_size=32, augment=True):\n",
    "    \"\"\"\n",
    "    Generates random data\n",
    "    \"\"\"\n",
    "    X = list(np.copy(X))\n",
    "    y = list(np.copy(y))\n",
    "    X_y = zip(X, y)\n",
    "    while True:\n",
    "        X_y_batch = random.sample(X_y, batch_size)\n",
    "        X_batch = [e[0] for e in X_y_batch]\n",
    "        y_batch = [e[1] for e in X_y_batch]\n",
    "        # Random augmentation        \n",
    "        for i, x in enumerate(X_batch):            \n",
    "            funcs2apply = random.sample(aug_funcs, np.random.randint(len(aug_funcs) + 1))\n",
    "            for f in funcs2apply:\n",
    "                x = f(x)\n",
    "            X_batch[i] = x\n",
    "        yield np.array(X_batch), np.array(y_batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[ -1.16807772e+00,  -9.59417592e-01],\n",
       "          [ -9.06588012e-01,  -1.87148443e-01],\n",
       "          [ -1.07884192e+00,   5.65464299e-01],\n",
       "          ..., \n",
       "          [  3.55944527e-01,   9.40027947e-01],\n",
       "          [ -3.63143729e-01,  -1.89424443e-01],\n",
       "          [ -1.17007645e+00,  -9.61757966e-01]],\n",
       " \n",
       "         [[ -9.91676047e-01,   1.03145272e+00],\n",
       "          [ -9.91676047e-01,   1.03145272e+00],\n",
       "          [ -1.45004770e+00,   1.53034195e+00],\n",
       "          ..., \n",
       "          [  8.53595234e-01,   8.48929430e-01],\n",
       "          [  5.29522737e-01,   2.56875874e-01],\n",
       "          [ -5.10785831e-01,  -8.22861500e-01]],\n",
       " \n",
       "         [[  1.12608308e-01,   2.59151874e-01],\n",
       "          [ -2.08984346e+00,   3.63715708e-01],\n",
       "          [ -1.16816015e+00,   7.58008428e-01],\n",
       "          ..., \n",
       "          [  4.72603099e-01,  -2.08719383e+00],\n",
       "          [  2.35370082e-01,  -8.22830776e-01],\n",
       "          [  1.73527916e-01,  -7.33957535e-02]],\n",
       " \n",
       "         ..., \n",
       "         [[ -1.35394185e+00,   5.65080983e-01],\n",
       "          [ -1.07919745e+00,   1.11834598e+00],\n",
       "          [  1.47108309e+00,   5.65016609e-01],\n",
       "          ..., \n",
       "          [  5.29165537e-01,  -9.62144208e-01],\n",
       "          [  8.53183080e-01,   2.56425746e-01],\n",
       "          [  9.55023696e-01,   6.60119462e-01]],\n",
       " \n",
       "         [[ -2.89975670e-01,   6.62430087e-01],\n",
       "          [ -1.54950698e+00,   8.50692879e-01],\n",
       "          [  1.19972210e+00,   8.50660204e-01],\n",
       "          ..., \n",
       "          [  8.01179725e-01,   6.60183836e-01],\n",
       "          [  6.40411161e-01,   4.63097460e-01],\n",
       "          [  1.73143656e-01,   1.36774914e+00]],\n",
       " \n",
       "         [[ -6.63097756e-01,  -5.56170103e-01],\n",
       "          [ -1.54950698e+00,   8.50692879e-01],\n",
       "          [ -2.19812585e-01,   9.41759697e-01],\n",
       "          ..., \n",
       "          [ -1.55139706e+00,   1.28556004e+00],\n",
       "          [ -5.87273598e-01,   1.11606900e+00],\n",
       "          [  2.34957928e-01,   3.60988605e-01]]],\n",
       " \n",
       " \n",
       "        [[[  5.20049018e-01,   6.64049198e-01],\n",
       "          [  2.43276037e-01,  -3.66121923e-01],\n",
       "          [ -4.90410390e-01,   6.64009439e-01],\n",
       "          ..., \n",
       "          [  9.37579087e-02,  -1.51377264e+00],\n",
       "          [  3.83697829e-01,  -1.51379079e+00],\n",
       "          [  7.72580510e-01,  -1.74962551e-01]],\n",
       " \n",
       "         [[ -1.42317098e-01,   9.52935875e-01],\n",
       "          [  7.73699558e-01,  -1.73582665e-01],\n",
       "          [ -1.42347570e-01,  -1.51245023e+00],\n",
       "          ..., \n",
       "          [ -7.81437486e-01,  -5.70415495e-01],\n",
       "          [ -5.85111627e-01,  -3.61441507e+00],\n",
       "          [  8.91899403e-01,  -5.70453525e-01]],\n",
       " \n",
       "         [[ -2.33440053e+00,   1.08943093e+00],\n",
       "          [ -9.90258157e-01,   5.10777700e-01],\n",
       "          [ -7.80381483e-01,   3.51001767e-01],\n",
       "          ..., \n",
       "          [ -1.10196857e+00,  -3.67463779e-01],\n",
       "          [ -5.85111627e-01,  -1.74943536e-01],\n",
       "          [  9.49847879e-01,  -1.51381067e+00]],\n",
       " \n",
       "         ..., \n",
       "         [[  3.14658694e-01,   1.70592493e+00],\n",
       "          [  1.00761493e+00,   1.08916126e+00],\n",
       "          [  1.79709229e+00,   9.52629906e-01],\n",
       "          ..., \n",
       "          [ -4.91700360e-01,  -7.85239070e-01],\n",
       "          [ -3.12709413e-01,  -1.25508226e+00],\n",
       "          [  2.41939834e-01,  -1.79225853e+00]],\n",
       " \n",
       "         [[  1.70892076e+00,   1.83912826e-01],\n",
       "          [  1.84024516e+00,  -1.73870483e-01],\n",
       "          [  1.61807087e+00,  -7.83936108e-01],\n",
       "          ..., \n",
       "          [ -6.25060308e-02,  -2.41928945e+00],\n",
       "          [  1.65015634e-02,  -5.70703745e-01],\n",
       "          [  7.72363005e-01,  -1.25510214e+00]],\n",
       " \n",
       "         [[  2.12631868e+00,   1.83912826e-01],\n",
       "          [  1.70890535e+00,   8.10964490e-01],\n",
       "          [  2.08703291e+00,   1.70586702e+00],\n",
       "          ..., \n",
       "          [  2.41970656e-01,   1.82571835e-01],\n",
       "          [ -6.25217921e-02,  -1.25508226e+00],\n",
       "          [  5.84123012e-01,  -5.70722760e-01]]],\n",
       " \n",
       " \n",
       "        [[[  1.57085448e+00,  -1.14371476e+00],\n",
       "          [  1.27660901e+00,   1.06606901e+00],\n",
       "          [  1.47533481e+00,   1.16469273e+00],\n",
       "          ..., \n",
       "          [  1.81667080e-02,  -8.09263910e-01],\n",
       "          [ -5.16474722e-01,   1.44815209e+00],\n",
       "          [  1.58022553e-01,   1.16618686e+00]],\n",
       " \n",
       "         [[  7.28594943e-01,  -1.50698061e+00],\n",
       "          [  9.57445143e-01,   2.97895365e-01],\n",
       "          [  8.44786085e-01,  -8.26710686e-02],\n",
       "          ..., \n",
       "          [ -4.35300231e-01,   6.46840603e-01],\n",
       "          [ -4.35300231e-01,   6.46840603e-01],\n",
       "          [ -7.71012056e-01,   2.03771025e+00]],\n",
       " \n",
       "         [[  7.28594943e-01,  -1.50698061e+00],\n",
       "          [ -1.28415654e-01,  -8.10735048e-01],\n",
       "          [  1.56610241e-01,  -8.10713441e-01],\n",
       "          ..., \n",
       "          [  8.87410350e-02,  -6.52625853e-01],\n",
       "          [ -5.16453863e-01,   1.35637422e+00],\n",
       "          [ -1.04396681e+00,   9.66509732e-01]],\n",
       " \n",
       "         ..., \n",
       "         [[  1.52391053e+00,   2.98438767e-01],\n",
       "          [  1.57123888e-01,   1.75585397e-01],\n",
       "          [  1.57123888e-01,   1.75585397e-01],\n",
       "          ..., \n",
       "          [  4.23499875e-01,   9.67005781e-01],\n",
       "          [  6.10725975e-01,  -3.56136805e-01],\n",
       "          [  3.59019349e-01,  -6.52040156e-01]],\n",
       " \n",
       "         [[  1.01306200e+00,  -8.10192566e-01],\n",
       "          [ -2.02626359e-01,   4.88073076e-02],\n",
       "          [  2.91963200e-01,  -8.21065194e-02],\n",
       "          ..., \n",
       "          [ -2.01216654e-01,  -2.16010894e-01],\n",
       "          [  6.10725975e-01,  -3.56136805e-01],\n",
       "          [  2.26566192e-01,  -1.31911443e+00]],\n",
       " \n",
       "         [[  1.32778730e+00,  -8.10192566e-01],\n",
       "          [  9.57980518e-01,   4.88073076e-02],\n",
       "          [  6.09337129e-01,  -3.57605644e-01],\n",
       "          ..., \n",
       "          [  2.93351612e-01,  -9.71685839e-01],\n",
       "          [  8.92955305e-02,   2.99976106e-01],\n",
       "          [  4.23563755e-01,   5.34958707e-01]]],\n",
       " \n",
       " \n",
       "        ..., \n",
       "        [[[  1.63885671e+00,   6.10477559e-01],\n",
       "          [  9.22800753e-01,  -4.57721296e-01],\n",
       "          [ -1.10138844e+00,  -1.01960911e+00],\n",
       "          ..., \n",
       "          [  1.00805799e+00,   7.41018180e-01],\n",
       "          [ -1.85296989e-01,  -8.24726405e-01],\n",
       "          [  1.49466632e-01,  -2.87920505e-01]],\n",
       " \n",
       "         [[  1.25759981e+00,   7.42298403e-01],\n",
       "          [  1.41464722e+00,  -1.01959152e+00],\n",
       "          [  6.51078732e-01,  -8.23462845e-01],\n",
       "          ..., \n",
       "          [  4.57452069e-01,  -2.87902917e-01],\n",
       "          [ -6.82463482e-01,   6.09161235e-01],\n",
       "          [  3.57475960e-01,   3.31777748e-01]],\n",
       " \n",
       "         [[  4.58695475e-01,   1.86907054e-01],\n",
       "          [  1.00926595e+00,  -2.75142582e+00],\n",
       "          [  7.43795514e-01,  -8.23462845e-01],\n",
       "          ..., \n",
       "          [  4.57452069e-01,  -8.24726405e-01],\n",
       "          [ -3.03710231e-01,  -1.91797199e+00],\n",
       "          [ -9.57422256e-01,  -1.67426726e+00]],\n",
       " \n",
       "         ..., \n",
       "         [[ -3.02621864e-01,  -4.57882828e-01],\n",
       "          [  1.50536838e-01,  -4.57900879e-01],\n",
       "          [  1.50519119e-01,   6.10260949e-01],\n",
       "          ..., \n",
       "          [ -1.85452470e-01,  -1.22724451e+00],\n",
       "          [  1.41324878e+00,  -1.23970972e-01],\n",
       "          [  5.54673372e-01,   3.36871403e-02]],\n",
       " \n",
       "         [[  1.50553670e-01,   1.45341596e+00],\n",
       "          [  5.55917221e-01,   4.73988021e-01],\n",
       "          [ -6.93997941e-02,   6.10260949e-01],\n",
       "          ..., \n",
       "          [ -5.52163689e-01,  -1.44460470e+00],\n",
       "          [  4.09226732e-02,  -2.88082963e-01],\n",
       "          [  4.09058405e-02,  -1.22727969e+00]],\n",
       " \n",
       "         [[  6.50940527e-01,   6.10297977e-01],\n",
       "          [  2.55956557e-01,   1.22999623e+00],\n",
       "          [ -1.84260892e-01,   1.22997772e+00],\n",
       "          ..., \n",
       "          [ -1.85469303e-01,   9.92164966e-01],\n",
       "          [ -7.06268101e-02,  -1.44464173e+00],\n",
       "          [  9.21367758e-01,  -8.24942553e-01]]],\n",
       " \n",
       " \n",
       "        [[[ -9.16911905e-01,  -4.48422736e-01],\n",
       "          [ -7.74449013e-01,  -6.53084579e-01],\n",
       "          [ -8.80327703e-01,  -4.48446309e-01],\n",
       "          ..., \n",
       "          [  2.66035533e-01,   7.25685800e-01],\n",
       "          [ -4.00919127e-01,   2.56420853e-03],\n",
       "          [  2.86101714e-01,   5.95921694e-01]],\n",
       " \n",
       "         [[ -7.06912034e-01,  -4.48422736e-01],\n",
       "          [ -4.00339076e-01,  -1.38285074e+00],\n",
       "          [ -6.74018918e-01,  -1.11672633e+00],\n",
       "          ..., \n",
       "          [ -2.37647688e-01,  -1.69053273e-01],\n",
       "          [ -2.37647688e-01,  -1.69053273e-01],\n",
       "          [  4.21197989e-01,   3.88611085e-01]],\n",
       " \n",
       "         [[ -3.17001869e-01,  -6.53084579e-01],\n",
       "          [ -3.17001869e-01,  -6.53084579e-01],\n",
       "          [ -6.74018918e-01,  -1.11672633e+00],\n",
       "          ..., \n",
       "          [  1.19360794e-01,  -7.62423310e-01],\n",
       "          [ -6.29307949e-02,  -3.52526521e-01],\n",
       "          [ -4.29522620e-01,  -8.18843303e-02]],\n",
       " \n",
       "         ..., \n",
       "         [[ -5.47826066e-01,  -8.75065957e-01],\n",
       "          [ -2.90191729e-01,  -8.13436784e-02],\n",
       "          [ -2.37275266e-01,   8.48957554e-02],\n",
       "          ..., \n",
       "          [  3.01491396e-02,   7.87985980e-01],\n",
       "          [ -3.72943251e-01,   4.59267491e-01],\n",
       "          [ -4.58722847e-01,   2.28133064e-03]],\n",
       " \n",
       "         [[ -1.72962265e+00,  -8.13320449e-02],\n",
       "          [ -9.17119758e-01,   1.64290148e-01],\n",
       "          [ -6.74217979e-01,   6.62100424e-01],\n",
       "          ..., \n",
       "          [ -1.11471970e-01,   2.40584824e-01],\n",
       "          [ -1.11480536e-01,   6.61313325e-01],\n",
       "          [  4.57937518e-01,  -3.52808481e-01]],\n",
       " \n",
       "         [[ -3.17200930e-01,   3.08128726e-03],\n",
       "          [ -3.17209496e-01,   2.41360901e-01],\n",
       "          [  1.62761772e-01,   1.64266881e-01],\n",
       "          ..., \n",
       "          [ -8.45168040e-01,  -1.69324211e-01],\n",
       "          [ -3.72951817e-01,   2.28133064e-03],\n",
       "          [  5.82022755e-01,  -8.21540439e-02]]],\n",
       " \n",
       " \n",
       "        [[[ -8.36115659e-02,   9.03367554e-01],\n",
       "          [  4.88688089e-01,   4.93212062e-02],\n",
       "          [  3.55751514e-01,   2.37679422e-01],\n",
       "          ..., \n",
       "          [ -2.35845839e+00,  -3.77953105e+00],\n",
       "          [ -1.35023650e+00,  -1.08568606e+00],\n",
       "          [  4.87660748e-01,   4.15183314e-01]],\n",
       " \n",
       "         [[ -1.63734359e-01,   2.37697071e-01],\n",
       "          [ -4.18150576e-01,   4.93043592e-02],\n",
       "          [ -4.18150576e-01,   4.93043592e-02],\n",
       "          ..., \n",
       "          [ -2.03325902e+00,  -8.27469883e-01],\n",
       "          [ -2.19135433e+00,  -1.51030115e-01],\n",
       "          [ -2.47126667e-01,  -5.87126837e-01]],\n",
       " \n",
       "         [[ -7.95922374e-01,   2.37697071e-01],\n",
       "          [ -6.96816335e-01,   4.93043592e-02],\n",
       "          [ -5.68247443e-03,  -3.61078928e-01],\n",
       "          ..., \n",
       "          [ -1.35022169e+00,  -3.62234155e-01],\n",
       "          [ -2.03327383e+00,  -1.51030115e-01],\n",
       "          [ -6.97828192e-01,   4.80977884e-02]],\n",
       " \n",
       "         ..., \n",
       "         [[  4.22796250e-01,  -1.08470091e+00],\n",
       "          [  6.15628927e-01,  -5.86140883e-01],\n",
       "          [  4.88473667e-01,  -8.26534871e-01],\n",
       "          ..., \n",
       "          [  1.32860757e+00,  -3.62473624e-01],\n",
       "          [  1.12687319e+00,   9.01905469e-01],\n",
       "          [  6.76156850e-01,   9.01887820e-01]],\n",
       " \n",
       "         [[  7.37484228e-01,   5.86175014e-01],\n",
       "          [  9.11211806e-01,   4.90833417e-02],\n",
       "          [  3.55551903e-01,  -1.50078256e-01],\n",
       "          ..., \n",
       "          [  5.51750702e-01,  -2.36709353e+00],\n",
       "          [  6.76170988e-01,   4.78759687e-02],\n",
       "          [  1.43089012e-01,  -3.62508120e-01]],\n",
       " \n",
       "         [[  2.16312938e-01,  -8.26518024e-01],\n",
       "          [ -5.86727453e-03,   4.90664946e-02],\n",
       "          [ -7.96150260e-01,   1.46172584e+00],\n",
       "          ..., \n",
       "          [  2.85769500e-01,  -8.27708550e-01],\n",
       "          [  6.90804426e-02,  -1.36480022e+00],\n",
       "          [ -5.09332763e-01,  -1.08594157e+00]]]]),\n",
       " array([0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gen_obj = data_generator(X_train, y_train, batch_size=32, aug_funcs=aug_funcs)\n",
    "next(gen_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_shape):\n",
    "    # Architecture\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    loss = losses.binary_crossentropy\n",
    "    optimizer = optimizers.Adam()\n",
    "    metrics = ['accuracy']\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    #     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model(input_shape=(75, 75, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "317/320 [============================>.] - ETA: 0s - loss: 0.6489 - acc: 0.5748Epoch 00000: val_loss improved from inf to 0.60458, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 6s - loss: 0.6487 - acc: 0.5755 - val_loss: 0.6046 - val_acc: 0.6219\n",
      "Epoch 2/200\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.5597 - acc: 0.6591Epoch 00001: val_loss improved from 0.60458 to 0.32088, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 5s - loss: 0.5593 - acc: 0.6594 - val_loss: 0.3209 - val_acc: 0.8656\n",
      "Epoch 3/200\n",
      "316/320 [============================>.] - ETA: 0s - loss: 0.5005 - acc: 0.6851Epoch 00002: val_loss improved from 0.32088 to 0.31882, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 5s - loss: 0.5003 - acc: 0.6842 - val_loss: 0.3188 - val_acc: 0.8531\n",
      "Epoch 4/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.4891 - acc: 0.6966Epoch 00003: val_loss improved from 0.31882 to 0.27398, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 5s - loss: 0.4891 - acc: 0.6964 - val_loss: 0.2740 - val_acc: 0.8906\n",
      "Epoch 5/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.4632 - acc: 0.7087Epoch 00004: val_loss improved from 0.27398 to 0.25520, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 5s - loss: 0.4636 - acc: 0.7087 - val_loss: 0.2552 - val_acc: 0.8906\n",
      "Epoch 6/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.4487 - acc: 0.7174Epoch 00005: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.4488 - acc: 0.7175 - val_loss: 0.2680 - val_acc: 0.8969\n",
      "Epoch 7/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.4382 - acc: 0.7268Epoch 00006: val_loss improved from 0.25520 to 0.25229, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 5s - loss: 0.4390 - acc: 0.7262 - val_loss: 0.2523 - val_acc: 0.8875\n",
      "Epoch 8/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.4444 - acc: 0.7246Epoch 00007: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.4441 - acc: 0.7252 - val_loss: 0.3016 - val_acc: 0.8844\n",
      "Epoch 9/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.4368 - acc: 0.7266Epoch 00008: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.4363 - acc: 0.7269 - val_loss: 0.2935 - val_acc: 0.8938\n",
      "Epoch 10/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.4333 - acc: 0.7295Epoch 00009: val_loss improved from 0.25229 to 0.24857, saving model to ./models/model6/model5.h5\n",
      "320/320 [==============================] - 5s - loss: 0.4336 - acc: 0.7289 - val_loss: 0.2486 - val_acc: 0.9031\n",
      "Epoch 11/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.4265 - acc: 0.7337Epoch 00010: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.4266 - acc: 0.7335 - val_loss: 0.2555 - val_acc: 0.9000\n",
      "Epoch 12/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.4204 - acc: 0.7329Epoch 00011: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.4202 - acc: 0.7331 - val_loss: 0.2597 - val_acc: 0.9219\n",
      "Epoch 13/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.4181 - acc: 0.7365Epoch 00012: val_loss did not improve\n",
      "\n",
      "Epoch 00012: reducing learning rate to 0.000500000023749.\n",
      "320/320 [==============================] - 5s - loss: 0.4179 - acc: 0.7367 - val_loss: 0.2692 - val_acc: 0.9125\n",
      "Epoch 14/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.4030 - acc: 0.7454Epoch 00013: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.4026 - acc: 0.7456 - val_loss: 0.3074 - val_acc: 0.9125\n",
      "Epoch 15/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.3916 - acc: 0.7518Epoch 00014: val_loss did not improve\n",
      "\n",
      "Epoch 00014: reducing learning rate to 0.000250000011874.\n",
      "320/320 [==============================] - 5s - loss: 0.3920 - acc: 0.7516 - val_loss: 0.3140 - val_acc: 0.9094\n",
      "Epoch 16/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.3937 - acc: 0.7465Epoch 00015: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.3934 - acc: 0.7466 - val_loss: 0.3094 - val_acc: 0.9187\n",
      "Epoch 17/200\n",
      "318/320 [============================>.] - ETA: 0s - loss: 0.3804 - acc: 0.7546Epoch 00016: val_loss did not improve\n",
      "\n",
      "Epoch 00016: reducing learning rate to 0.000125000005937.\n",
      "320/320 [==============================] - 5s - loss: 0.3803 - acc: 0.7547 - val_loss: 0.3068 - val_acc: 0.9125\n",
      "Epoch 18/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.3884 - acc: 0.7496Epoch 00017: val_loss did not improve\n",
      "320/320 [==============================] - 5s - loss: 0.3886 - acc: 0.7496 - val_loss: 0.3524 - val_acc: 0.9031\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f58cd0be250>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callbacks\n",
    "def get_lr(epoch):\n",
    "    lr = (np.random.rand() * 1e-3 + 1e-7)\n",
    "    print 'lr:', lr\n",
    "    return lr\n",
    "MODEL_PATH = './models/model6/model' + str(MODEL_NUMBER) + '.h5'\n",
    "m_q = 'val_loss'\n",
    "model_path = MODEL_PATH\n",
    "check_pt = callbacks.ModelCheckpoint(filepath=model_path, monitor=m_q, save_best_only=True, verbose=1)\n",
    "early_stop = callbacks.EarlyStopping(patience=7, monitor=m_q, verbose=1)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(patience=2, factor=0.5, monitor=m_q, verbose=1)\n",
    "schedule_lr = callbacks.LearningRateScheduler(get_lr)\n",
    "callback_list = [check_pt, early_stop, reduce_lr]\n",
    "\n",
    "# Fit generator\n",
    "batch_size = 32\n",
    "steps_per_epoch = (len(X_train) / batch_size) * 8\n",
    "gen_obj = data_generator(X_train, y_train, batch_size=batch_size, aug_funcs=aug_funcs)\n",
    "model.fit_generator(gen_obj, steps_per_epoch=steps_per_epoch, validation_data=(X_val, y_val), callbacks=callback_list, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Finetune\n",
    "# loss = losses.binary_crossentropy\n",
    "# optimizer = optimizers.SGD(lr=1e-4)\n",
    "# metrics = ['accuracy']\n",
    "# model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# m_q = 'val_loss'\n",
    "# model_path = MODEL_PATH\n",
    "# check_pt = callbacks.ModelCheckpoint(filepath=model_path, monitor=m_q, save_best_only=True, verbose=1)\n",
    "# early_stop = callbacks.EarlyStopping(patience=5, monitor=m_q, verbose=1)\n",
    "# reduce_lr = callbacks.ReduceLROnPlateau(patience=2, factor=0.33, monitor=m_q, verbose=1)\n",
    "# callback_list = [check_pt, early_stop, reduce_lr]\n",
    "\n",
    "# model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=callback_list, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape: (8424, 75, 75, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "df = pd.read_json('./data/test.json')\n",
    "X_test, y_test = [], []\n",
    "for im_band1, im_band2 in zip(df['band_1'], df['band_2']):\n",
    "    im_band1 = np.array(im_band1).reshape(75, 75, 1)\n",
    "    im_band2 = np.array(im_band2).reshape(75, 75, 1)    \n",
    "    # Preprocess - zero mean\n",
    "    im_band1 -= np.mean(im_band1)\n",
    "    im_band2 -= np.mean(im_band2)\n",
    "    # Preprocess - normalize\n",
    "    im_band1 /= np.std(im_band1)\n",
    "    im_band2 /= np.std(im_band2)    \n",
    "    im = np.concatenate([im_band1, im_band2], axis=2)\n",
    "    X_test.append(im)    \n",
    "X_test = np.array(X_test)\n",
    "print 'X_test.shape:', X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict - tta\n",
    "def bypass(x):\n",
    "    return x\n",
    "\n",
    "def h_flip(x):\n",
    "    return x[:, :, ::-1, :]\n",
    "\n",
    "def v_flip(x):\n",
    "    return x[:, ::-1, :, :]\n",
    "\n",
    "def hv_flip(x):\n",
    "    return h_flip(v_flip(x))\n",
    "\n",
    "def rot90(x):\n",
    "    return np.concatenate([np.expand_dims(transform.rotate(im, 90), axis=0) for im in x], axis=0)\n",
    "\n",
    "def rot180(x):\n",
    "    return np.concatenate([np.expand_dims(transform.rotate(im, 180), axis=0) for im in x], axis=0)\n",
    "\n",
    "def rot270(x):\n",
    "    return np.concatenate([np.expand_dims(transform.rotate(im, 270), axis=0) for im in x], axis=0)\n",
    "\n",
    "tta_aug_funcs = [bypass, \n",
    "                 h_flip, v_flip, hv_flip,\n",
    "                 rot90, rot180, rot270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "8424/8424 [==============================] - 1s     \n",
      "8424/8424 [==============================] - 1s     \n",
      "8288/8424 [============================>.] - ETA: 0s1\n",
      "8416/8424 [============================>.] - ETA: 0s2\n",
      "8352/8424 [============================>.] - ETA: 0s3\n",
      "8424/8424 [==============================] - 1s     \n",
      "8424/8424 [==============================] - 1s     \n",
      "4\n",
      "8424/8424 [==============================] - 1s     \n",
      "8384/8424 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_test_p = 0\n",
    "weights = [0.25, 0.5 / 3, 0.25, 0.5 / 3, 0.5 / 3]\n",
    "for i, w in zip(range(5), weights):\n",
    "    print i\n",
    "    # Load the model\n",
    "    MODEL_PATH = './models/model6/model' + str(i + 1) + '.h5'\n",
    "    model = load_model(MODEL_PATH)\n",
    "    # predict - tta    \n",
    "    for func in tta_aug_funcs:\n",
    "        y_test_p += model.predict(func(X_test), verbose=1).flatten() * w\n",
    "# y_test_p = y_test_p / (len(aug_funcs) * 5.0)\n",
    "y_test_p = y_test_p / (len(tta_aug_funcs) * sum(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame()\n",
    "df_sub['id'] = df['id']\n",
    "df_sub['is_iceberg'] = y_test_p.flatten()\n",
    "df_sub.to_csv('./submissions/sub16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
