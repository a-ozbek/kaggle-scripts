{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "\n",
    "* Add FFT channels to CNN (Tried, does not make much difference)\n",
    "* Finetune CNN (with SGD slow learning rate)\n",
    "* 5-fold CNN\n",
    "* Extract Features from CNN (before FC) and do XGB\n",
    "* TTA (tried, made it better)\n",
    "* More augmenting, additional 45, 135, 315 degrees\n",
    "* More augmenting, random rotations and flips\n",
    "* Predict test data and train with test\n",
    "* Train on all of the training data (no train-val split)\n",
    "* Try a different combination of combine predictions\n",
    "* Fine-tune on pre-trained models (Get rid of some top layers because input size is small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, no augmentation, no add test data margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Create Dataset](#Create-Dataset)\n",
    "* [Train - Val Split](#Train---Val-Split)\n",
    "* [Data Augmentation](#Data-Augmentation)\n",
    "* [Training](#Training)\n",
    "* [Predict Test](#Predict-Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/can/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import transform\n",
    "from keras import layers\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, LeakyReLU, concatenate\n",
    "from keras import losses, optimizers, callbacks\n",
    "from keras import regularizers\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.signal import fftconvolve\n",
    "from sklearn.model_selection import cross_validate, train_test_split, StratifiedKFold, KFold\n",
    "from scipy import fftpack\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "RANDOM_SEED = 43\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bypass(x):\n",
    "    return x\n",
    "\n",
    "def h_flip(x):\n",
    "    return x[:, :, ::-1, :]\n",
    "\n",
    "def v_flip(x):\n",
    "    return x[:, ::-1, :, :]\n",
    "\n",
    "def hv_flip(x):\n",
    "    return h_flip(v_flip(x))\n",
    "\n",
    "def rot90(x):\n",
    "    return np.concatenate([np.expand_dims(transform.rotate(im, 90), axis=0) for im in x], axis=0)\n",
    "\n",
    "def rot180(x):\n",
    "    return np.concatenate([np.expand_dims(transform.rotate(im, 180), axis=0) for im in x], axis=0)\n",
    "\n",
    "def rot270(x):\n",
    "    return np.concatenate([np.expand_dims(transform.rotate(im, 270), axis=0) for im in x], axis=0)\n",
    "\n",
    "def rot45(x):\n",
    "    return np.concatenate([np.expand_dims(transform.rotate(im, 45, mode='reflect'), axis=0) for im in x], axis=0)\n",
    "\n",
    "def rot135(x):\n",
    "    return np.concatenate([np.expand_dims(transform.rotate(im, 135, mode='reflect'), axis=0) for im in x], axis=0)\n",
    "\n",
    "def rot315(x):\n",
    "    return np.concatenate([np.expand_dims(transform.rotate(im, 315, mode='reflect'), axis=0) for im in x], axis=0)\n",
    "\n",
    "aug_funcs = [bypass, \n",
    "             h_flip, v_flip, hv_flip,\n",
    "             rot90, rot180, rot270]\n",
    "\n",
    "aug_funcs = [bypass]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "df_train = pd.read_json('./data/train-angle-filled.json')\n",
    "df = df_train\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-27.878361, -27.15416, -28.668615, -29.537971...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>dfd5f913</td>\n",
       "      <td>43.923900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-12.242375, -14.920305, -14.920363, -12.66633...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>e25388fd</td>\n",
       "      <td>38.156200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-21.397552, -19.753859, -23.426783, -24.65221...</td>\n",
       "      <td>[-26.72291, -27.418192, -27.787899, -25.774536...</td>\n",
       "      <td>3aac67cd</td>\n",
       "      <td>44.624000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[-20.04884, -19.469616, -20.510244, -19.61095,...</td>\n",
       "      <td>[-29.742329, -26.374287, -25.490265, -25.49031...</td>\n",
       "      <td>66348d03</td>\n",
       "      <td>41.134200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>[-23.199345, -23.603487, -25.965549, -27.12546...</td>\n",
       "      <td>[-23.004148, -24.942425, -24.472878, -23.00437...</td>\n",
       "      <td>7052a617</td>\n",
       "      <td>33.897500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>[-22.34741, -22.156555, -25.308764, -24.530453...</td>\n",
       "      <td>[-24.782082, -24.047678, -24.782185, -27.45301...</td>\n",
       "      <td>3062fca8</td>\n",
       "      <td>39.962700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>[-20.845585, -17.811007, -20.689199, -21.84909...</td>\n",
       "      <td>[-26.110413, -25.549898, -25.549961, -26.70986...</td>\n",
       "      <td>4ea48c18</td>\n",
       "      <td>37.326000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>[-25.098461, -25.098461, -24.320147, -21.05014...</td>\n",
       "      <td>[-29.62639, -29.62639, -28.757122, -29.180954,...</td>\n",
       "      <td>b7519a52</td>\n",
       "      <td>42.559000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>[-25.847187, -20.741787, -19.826689, -18.99888...</td>\n",
       "      <td>[-25.562378, -23.348463, -26.76244, -30.780788...</td>\n",
       "      <td>ed4a2968</td>\n",
       "      <td>40.395800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>[-19.860071, -19.443127, -18.789801, -19.44324...</td>\n",
       "      <td>[-29.12228, -26.939449, -27.267315, -29.54624,...</td>\n",
       "      <td>5d58d936</td>\n",
       "      <td>38.853700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>[-21.582905, -15.472338, -16.417433, -16.72227...</td>\n",
       "      <td>[-25.104729, -24.326412, -28.763432, -32.92899...</td>\n",
       "      <td>204941f0</td>\n",
       "      <td>42.466400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>[-15.922758, -18.05191, -20.081108, -21.756691...</td>\n",
       "      <td>[-27.59429, -29.177961, -27.964048, -25.656225...</td>\n",
       "      <td>a4640b34</td>\n",
       "      <td>42.551100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>[-16.034737, -18.847061, -19.510372, -19.37352...</td>\n",
       "      <td>[-24.371244, -25.954815, -29.052799, -26.24916...</td>\n",
       "      <td>51cc4525</td>\n",
       "      <td>38.917700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>[-18.872736, -18.396748, -20.191444, -20.19144...</td>\n",
       "      <td>[-23.856705, -26.954813, -22.456083, -22.45608...</td>\n",
       "      <td>a02ce286</td>\n",
       "      <td>35.295400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[-13.271194, -12.898959, -14.867657, -16.54327...</td>\n",
       "      <td>[-22.941357, -23.540695, -24.41008, -24.879778...</td>\n",
       "      <td>f9209504</td>\n",
       "      <td>35.687314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>[-18.296215, -18.296215, -19.159414, -19.42270...</td>\n",
       "      <td>[-22.425694, -22.425694, -24.554861, -25.05139...</td>\n",
       "      <td>3b716f7c</td>\n",
       "      <td>36.905200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>[-25.227173, -26.75498, -28.206034, -24.684248...</td>\n",
       "      <td>[-28.205952, -27.095646, -23.458815, -24.68424...</td>\n",
       "      <td>cd9bfc19</td>\n",
       "      <td>44.598400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>[-13.523142, -10.304675, -11.433078, -9.585804...</td>\n",
       "      <td>[-21.386665, -21.076504, -20.776958, -22.21468...</td>\n",
       "      <td>204afe46</td>\n",
       "      <td>32.801000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>[-14.079979, -12.444381, -13.330808, -17.96138...</td>\n",
       "      <td>[-24.356861, -25.444052, -26.359238, -24.35697...</td>\n",
       "      <td>a7cbade6</td>\n",
       "      <td>45.231100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>[-22.005711, -19.372328, -19.372389, -24.26668...</td>\n",
       "      <td>[-28.026312, -26.687433, -25.527657, -24.50466...</td>\n",
       "      <td>47f0178a</td>\n",
       "      <td>38.073600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>[-20.841007, -21.928198, -24.362909, -26.36525...</td>\n",
       "      <td>[-26.692944, -25.450024, -26.69302, -29.417456...</td>\n",
       "      <td>47377a6d</td>\n",
       "      <td>45.281400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>[-15.594682, -17.752846, -16.509949, -14.92638...</td>\n",
       "      <td>[-23.773388, -23.553539, -25.767563, -27.99063...</td>\n",
       "      <td>d782d1a6</td>\n",
       "      <td>38.012000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>[-15.246128, -21.423317, -14.941492, -13.88530...</td>\n",
       "      <td>[-24.409197, -21.113071, -23.166401, -26.68830...</td>\n",
       "      <td>97c1936d</td>\n",
       "      <td>32.397600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>[-8.980766, -7.830616, -7.830616, -14.773924, ...</td>\n",
       "      <td>[-15.39446, -18.916361, -18.916361, -23.598099...</td>\n",
       "      <td>c04a768c</td>\n",
       "      <td>33.634000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>[-19.839947, -18.951641, -17.110567, -16.01201...</td>\n",
       "      <td>[-24.276922, -23.633305, -24.734333, -25.99544...</td>\n",
       "      <td>1a9b4671</td>\n",
       "      <td>33.151800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>[-22.781437, -25.155306, -25.407164, -24.91069...</td>\n",
       "      <td>[-25.933594, -25.933668, -22.97249, -22.97249,...</td>\n",
       "      <td>68a80de0</td>\n",
       "      <td>33.635200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>[-23.397076, -23.397121, -22.349405, -21.41458...</td>\n",
       "      <td>[-29.643297, -29.197815, -29.643387, -30.11305...</td>\n",
       "      <td>4575aa18</td>\n",
       "      <td>42.565600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>[-21.622839, -26.121675, -23.938826, -21.62296...</td>\n",
       "      <td>[-30.982395, -30.455856, -30.982477, -29.95946...</td>\n",
       "      <td>2a3f1b90</td>\n",
       "      <td>24.754600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>[-25.847713, -30.099937, -28.070847, -23.41945...</td>\n",
       "      <td>[-22.805897, -22.61076, -22.610819, -22.610882...</td>\n",
       "      <td>b4c0ff45</td>\n",
       "      <td>37.254000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>[-25.014416, -22.861778, -24.747219, -22.24848...</td>\n",
       "      <td>[-30.011963, -28.673069, -28.673113, -28.67315...</td>\n",
       "      <td>1abf7cc6</td>\n",
       "      <td>43.940700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>[-11.428017, -14.924254, -13.707028, -10.83239...</td>\n",
       "      <td>[-22.730595, -22.730667, -25.615616, -25.88296...</td>\n",
       "      <td>11745012</td>\n",
       "      <td>34.760800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>[-23.783607, -23.106487, -22.892052, -27.91321...</td>\n",
       "      <td>[-31.065243, -30.042236, -31.625904, -29.57270...</td>\n",
       "      <td>5d500eef</td>\n",
       "      <td>43.122500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>[-20.725979, -21.93195, -19.956917, -18.98313,...</td>\n",
       "      <td>[-24.247807, -23.118229, -24.247906, -26.12604...</td>\n",
       "      <td>25099fdb</td>\n",
       "      <td>40.406700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>[-25.046005, -24.290234, -25.046059, -24.53502...</td>\n",
       "      <td>[-24.290234, -28.181726, -27.457535, -27.11692...</td>\n",
       "      <td>af64e5df</td>\n",
       "      <td>39.979800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>[-18.194069, -19.217171, -18.94994, -20.85535,...</td>\n",
       "      <td>[-28.492268, -27.041302, -24.459457, -24.71128...</td>\n",
       "      <td>42d5bfdb</td>\n",
       "      <td>41.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>[-27.796564, -27.796564, -25.858414, -26.15293...</td>\n",
       "      <td>[-25.858364, -25.858364, -27.442039, -25.03061...</td>\n",
       "      <td>8f7cfa57</td>\n",
       "      <td>39.979800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>[-15.981394, -15.145637, -16.339764, -16.52464...</td>\n",
       "      <td>[-27.935297, -26.646206, -23.853037, -22.26948...</td>\n",
       "      <td>b95d879e</td>\n",
       "      <td>35.629200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>[-22.723167, -24.191811, -22.723295, -21.98369...</td>\n",
       "      <td>[-23.118048, -25.684483, -24.423513, -21.80821...</td>\n",
       "      <td>492b5f24</td>\n",
       "      <td>36.105800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[-29.021114, -24.835978, -24.836033, -25.92323...</td>\n",
       "      <td>[-28.230946, -26.838282, -28.231052, -30.85668...</td>\n",
       "      <td>3e21b615</td>\n",
       "      <td>39.583500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>[-24.981125, -24.713886, -26.45693, -24.713966...</td>\n",
       "      <td>[-29.50905, -27.849607, -29.509134, -30.475269...</td>\n",
       "      <td>59faf76c</td>\n",
       "      <td>43.920400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>[-25.825684, -24.997881, -23.546917, -23.32706...</td>\n",
       "      <td>[-25.26511, -30.759182, -23.546917, -27.068794...</td>\n",
       "      <td>3bc6f607</td>\n",
       "      <td>40.711800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>[-26.367798, -24.11375, -21.930901, -22.73951,...</td>\n",
       "      <td>[-26.695606, -29.42004, -27.03635, -26.367912,...</td>\n",
       "      <td>cc93f030</td>\n",
       "      <td>45.281400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>[-24.35783, -24.884445, -22.946283, -21.362698...</td>\n",
       "      <td>[-24.106047, -22.118393, -26.044323, -27.75296...</td>\n",
       "      <td>0498f9ab</td>\n",
       "      <td>45.285900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>[-24.351328, -24.610664, -24.351404, -26.03785...</td>\n",
       "      <td>[-26.35363, -25.153709, -25.153748, -23.616983...</td>\n",
       "      <td>cf7a269a</td>\n",
       "      <td>45.384600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>[-16.572922, -16.976988, -17.961403, -20.34518...</td>\n",
       "      <td>[-27.503775, -27.503775, -27.858402, -24.83310...</td>\n",
       "      <td>57efa83d</td>\n",
       "      <td>39.217500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>[-30.137747, -27.639019, -28.798904, -28.79895...</td>\n",
       "      <td>[-32.964329, -32.320683, -32.964424, -31.72151...</td>\n",
       "      <td>6fa53d41</td>\n",
       "      <td>41.916500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>[-21.547363, -21.378761, -22.829836, -22.63470...</td>\n",
       "      <td>[-25.595764, -28.464272, -26.45093, -25.328672...</td>\n",
       "      <td>4b951984</td>\n",
       "      <td>37.280200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>[-14.316916, -13.959422, -22.95887, -16.840189...</td>\n",
       "      <td>[-21.676453, -22.3859, -21.180048, -22.203163,...</td>\n",
       "      <td>89d05291</td>\n",
       "      <td>36.121500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>[-22.211008, -23.48443, -23.716108, -22.211132...</td>\n",
       "      <td>[-29.974611, -29.059504, -28.635757, -27.84562...</td>\n",
       "      <td>a52bd61e</td>\n",
       "      <td>43.945900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[-14.393024, -14.393024, -11.607156, -13.10652...</td>\n",
       "      <td>[-20.635405, -20.635405, -21.256159, -22.10018...</td>\n",
       "      <td>8a1c5528</td>\n",
       "      <td>35.294500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>[-22.234995, -21.662136, -25.001135, -21.84902...</td>\n",
       "      <td>[-29.08345, -29.998642, -29.998684, -26.80471,...</td>\n",
       "      <td>548cff84</td>\n",
       "      <td>43.946000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>[-20.842922, -21.552406, -25.451977, -24.36486...</td>\n",
       "      <td>[-24.624046, -26.051201, -25.167168, -24.62416...</td>\n",
       "      <td>b764665a</td>\n",
       "      <td>45.280900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>[-26.212193, -24.443829, -26.212339, -25.93664...</td>\n",
       "      <td>[-23.370056, -22.784344, -23.170521, -21.88824...</td>\n",
       "      <td>2c4668f9</td>\n",
       "      <td>34.002100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>[-27.015923, -26.10083, -23.38764, -21.157799,...</td>\n",
       "      <td>[-26.700037, -28.039034, -25.013737, -26.70015...</td>\n",
       "      <td>8b2054f8</td>\n",
       "      <td>38.014400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>[-27.942827, -29.102724, -28.698711, -30.93824...</td>\n",
       "      <td>[-29.971981, -27.588308, -27.588366, -26.29926...</td>\n",
       "      <td>74725cf4</td>\n",
       "      <td>38.475500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[-18.494432, -21.417046, -24.032461, -21.07648...</td>\n",
       "      <td>[-24.515034, -25.854019, -29.375896, -27.09708...</td>\n",
       "      <td>364a544e</td>\n",
       "      <td>40.395800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[-19.969954, -19.97002, -17.64822, -15.645983,...</td>\n",
       "      <td>[-25.714788, -24.691803, -27.859119, -25.99075...</td>\n",
       "      <td>d0a54ee0</td>\n",
       "      <td>36.691570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[-26.522552, -21.661846, -18.081186, -19.34227...</td>\n",
       "      <td>[-30.856735, -26.522608, -26.522659, -27.16640...</td>\n",
       "      <td>2d272de7</td>\n",
       "      <td>39.698200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[-28.344879, -26.566103, -26.566147, -24.56388...</td>\n",
       "      <td>[-31.110933, -32.270817, -31.111023, -30.58448...</td>\n",
       "      <td>308fc1fe</td>\n",
       "      <td>42.462500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[-15.976473, -15.220771, -14.233538, -13.21853...</td>\n",
       "      <td>[-24.525143, -24.293573, -23.633568, -21.56924...</td>\n",
       "      <td>17018107</td>\n",
       "      <td>35.294500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 band_1  \\\n",
       "0     [-27.878361, -27.15416, -28.668615, -29.537971...   \n",
       "1     [-12.242375, -14.920305, -14.920363, -12.66633...   \n",
       "10    [-21.397552, -19.753859, -23.426783, -24.65221...   \n",
       "100   [-20.04884, -19.469616, -20.510244, -19.61095,...   \n",
       "1000  [-23.199345, -23.603487, -25.965549, -27.12546...   \n",
       "1001  [-22.34741, -22.156555, -25.308764, -24.530453...   \n",
       "1002  [-20.845585, -17.811007, -20.689199, -21.84909...   \n",
       "1003  [-25.098461, -25.098461, -24.320147, -21.05014...   \n",
       "1004  [-25.847187, -20.741787, -19.826689, -18.99888...   \n",
       "1005  [-19.860071, -19.443127, -18.789801, -19.44324...   \n",
       "1006  [-21.582905, -15.472338, -16.417433, -16.72227...   \n",
       "1007  [-15.922758, -18.05191, -20.081108, -21.756691...   \n",
       "1008  [-16.034737, -18.847061, -19.510372, -19.37352...   \n",
       "1009  [-18.872736, -18.396748, -20.191444, -20.19144...   \n",
       "101   [-13.271194, -12.898959, -14.867657, -16.54327...   \n",
       "1010  [-18.296215, -18.296215, -19.159414, -19.42270...   \n",
       "1011  [-25.227173, -26.75498, -28.206034, -24.684248...   \n",
       "1012  [-13.523142, -10.304675, -11.433078, -9.585804...   \n",
       "1013  [-14.079979, -12.444381, -13.330808, -17.96138...   \n",
       "1014  [-22.005711, -19.372328, -19.372389, -24.26668...   \n",
       "1015  [-20.841007, -21.928198, -24.362909, -26.36525...   \n",
       "1016  [-15.594682, -17.752846, -16.509949, -14.92638...   \n",
       "1017  [-15.246128, -21.423317, -14.941492, -13.88530...   \n",
       "1018  [-8.980766, -7.830616, -7.830616, -14.773924, ...   \n",
       "1019  [-19.839947, -18.951641, -17.110567, -16.01201...   \n",
       "102   [-22.781437, -25.155306, -25.407164, -24.91069...   \n",
       "1020  [-23.397076, -23.397121, -22.349405, -21.41458...   \n",
       "1021  [-21.622839, -26.121675, -23.938826, -21.62296...   \n",
       "1022  [-25.847713, -30.099937, -28.070847, -23.41945...   \n",
       "1023  [-25.014416, -22.861778, -24.747219, -22.24848...   \n",
       "...                                                 ...   \n",
       "972   [-11.428017, -14.924254, -13.707028, -10.83239...   \n",
       "973   [-23.783607, -23.106487, -22.892052, -27.91321...   \n",
       "974   [-20.725979, -21.93195, -19.956917, -18.98313,...   \n",
       "975   [-25.046005, -24.290234, -25.046059, -24.53502...   \n",
       "976   [-18.194069, -19.217171, -18.94994, -20.85535,...   \n",
       "977   [-27.796564, -27.796564, -25.858414, -26.15293...   \n",
       "978   [-15.981394, -15.145637, -16.339764, -16.52464...   \n",
       "979   [-22.723167, -24.191811, -22.723295, -21.98369...   \n",
       "98    [-29.021114, -24.835978, -24.836033, -25.92323...   \n",
       "980   [-24.981125, -24.713886, -26.45693, -24.713966...   \n",
       "981   [-25.825684, -24.997881, -23.546917, -23.32706...   \n",
       "982   [-26.367798, -24.11375, -21.930901, -22.73951,...   \n",
       "983   [-24.35783, -24.884445, -22.946283, -21.362698...   \n",
       "984   [-24.351328, -24.610664, -24.351404, -26.03785...   \n",
       "985   [-16.572922, -16.976988, -17.961403, -20.34518...   \n",
       "986   [-30.137747, -27.639019, -28.798904, -28.79895...   \n",
       "987   [-21.547363, -21.378761, -22.829836, -22.63470...   \n",
       "988   [-14.316916, -13.959422, -22.95887, -16.840189...   \n",
       "989   [-22.211008, -23.48443, -23.716108, -22.211132...   \n",
       "99    [-14.393024, -14.393024, -11.607156, -13.10652...   \n",
       "990   [-22.234995, -21.662136, -25.001135, -21.84902...   \n",
       "991   [-20.842922, -21.552406, -25.451977, -24.36486...   \n",
       "992   [-26.212193, -24.443829, -26.212339, -25.93664...   \n",
       "993   [-27.015923, -26.10083, -23.38764, -21.157799,...   \n",
       "994   [-27.942827, -29.102724, -28.698711, -30.93824...   \n",
       "995   [-18.494432, -21.417046, -24.032461, -21.07648...   \n",
       "996   [-19.969954, -19.97002, -17.64822, -15.645983,...   \n",
       "997   [-26.522552, -21.661846, -18.081186, -19.34227...   \n",
       "998   [-28.344879, -26.566103, -26.566147, -24.56388...   \n",
       "999   [-15.976473, -15.220771, -14.233538, -13.21853...   \n",
       "\n",
       "                                                 band_2        id  inc_angle  \\\n",
       "0     [-27.154118, -29.537888, -31.0306, -32.190483,...  dfd5f913  43.923900   \n",
       "1     [-31.506321, -27.984554, -26.645678, -23.76760...  e25388fd  38.156200   \n",
       "10    [-26.72291, -27.418192, -27.787899, -25.774536...  3aac67cd  44.624000   \n",
       "100   [-29.742329, -26.374287, -25.490265, -25.49031...  66348d03  41.134200   \n",
       "1000  [-23.004148, -24.942425, -24.472878, -23.00437...  7052a617  33.897500   \n",
       "1001  [-24.782082, -24.047678, -24.782185, -27.45301...  3062fca8  39.962700   \n",
       "1002  [-26.110413, -25.549898, -25.549961, -26.70986...  4ea48c18  37.326000   \n",
       "1003  [-29.62639, -29.62639, -28.757122, -29.180954,...  b7519a52  42.559000   \n",
       "1004  [-25.562378, -23.348463, -26.76244, -30.780788...  ed4a2968  40.395800   \n",
       "1005  [-29.12228, -26.939449, -27.267315, -29.54624,...  5d58d936  38.853700   \n",
       "1006  [-25.104729, -24.326412, -28.763432, -32.92899...  204941f0  42.466400   \n",
       "1007  [-27.59429, -29.177961, -27.964048, -25.656225...  a4640b34  42.551100   \n",
       "1008  [-24.371244, -25.954815, -29.052799, -26.24916...  51cc4525  38.917700   \n",
       "1009  [-23.856705, -26.954813, -22.456083, -22.45608...  a02ce286  35.295400   \n",
       "101   [-22.941357, -23.540695, -24.41008, -24.879778...  f9209504  35.687314   \n",
       "1010  [-22.425694, -22.425694, -24.554861, -25.05139...  3b716f7c  36.905200   \n",
       "1011  [-28.205952, -27.095646, -23.458815, -24.68424...  cd9bfc19  44.598400   \n",
       "1012  [-21.386665, -21.076504, -20.776958, -22.21468...  204afe46  32.801000   \n",
       "1013  [-24.356861, -25.444052, -26.359238, -24.35697...  a7cbade6  45.231100   \n",
       "1014  [-28.026312, -26.687433, -25.527657, -24.50466...  47f0178a  38.073600   \n",
       "1015  [-26.692944, -25.450024, -26.69302, -29.417456...  47377a6d  45.281400   \n",
       "1016  [-23.773388, -23.553539, -25.767563, -27.99063...  d782d1a6  38.012000   \n",
       "1017  [-24.409197, -21.113071, -23.166401, -26.68830...  97c1936d  32.397600   \n",
       "1018  [-15.39446, -18.916361, -18.916361, -23.598099...  c04a768c  33.634000   \n",
       "1019  [-24.276922, -23.633305, -24.734333, -25.99544...  1a9b4671  33.151800   \n",
       "102   [-25.933594, -25.933668, -22.97249, -22.97249,...  68a80de0  33.635200   \n",
       "1020  [-29.643297, -29.197815, -29.643387, -30.11305...  4575aa18  42.565600   \n",
       "1021  [-30.982395, -30.455856, -30.982477, -29.95946...  2a3f1b90  24.754600   \n",
       "1022  [-22.805897, -22.61076, -22.610819, -22.610882...  b4c0ff45  37.254000   \n",
       "1023  [-30.011963, -28.673069, -28.673113, -28.67315...  1abf7cc6  43.940700   \n",
       "...                                                 ...       ...        ...   \n",
       "972   [-22.730595, -22.730667, -25.615616, -25.88296...  11745012  34.760800   \n",
       "973   [-31.065243, -30.042236, -31.625904, -29.57270...  5d500eef  43.122500   \n",
       "974   [-24.247807, -23.118229, -24.247906, -26.12604...  25099fdb  40.406700   \n",
       "975   [-24.290234, -28.181726, -27.457535, -27.11692...  af64e5df  39.979800   \n",
       "976   [-28.492268, -27.041302, -24.459457, -24.71128...  42d5bfdb  41.200000   \n",
       "977   [-25.858364, -25.858364, -27.442039, -25.03061...  8f7cfa57  39.979800   \n",
       "978   [-27.935297, -26.646206, -23.853037, -22.26948...  b95d879e  35.629200   \n",
       "979   [-23.118048, -25.684483, -24.423513, -21.80821...  492b5f24  36.105800   \n",
       "98    [-28.230946, -26.838282, -28.231052, -30.85668...  3e21b615  39.583500   \n",
       "980   [-29.50905, -27.849607, -29.509134, -30.475269...  59faf76c  43.920400   \n",
       "981   [-25.26511, -30.759182, -23.546917, -27.068794...  3bc6f607  40.711800   \n",
       "982   [-26.695606, -29.42004, -27.03635, -26.367912,...  cc93f030  45.281400   \n",
       "983   [-24.106047, -22.118393, -26.044323, -27.75296...  0498f9ab  45.285900   \n",
       "984   [-26.35363, -25.153709, -25.153748, -23.616983...  cf7a269a  45.384600   \n",
       "985   [-27.503775, -27.503775, -27.858402, -24.83310...  57efa83d  39.217500   \n",
       "986   [-32.964329, -32.320683, -32.964424, -31.72151...  6fa53d41  41.916500   \n",
       "987   [-25.595764, -28.464272, -26.45093, -25.328672...  4b951984  37.280200   \n",
       "988   [-21.676453, -22.3859, -21.180048, -22.203163,...  89d05291  36.121500   \n",
       "989   [-29.974611, -29.059504, -28.635757, -27.84562...  a52bd61e  43.945900   \n",
       "99    [-20.635405, -20.635405, -21.256159, -22.10018...  8a1c5528  35.294500   \n",
       "990   [-29.08345, -29.998642, -29.998684, -26.80471,...  548cff84  43.946000   \n",
       "991   [-24.624046, -26.051201, -25.167168, -24.62416...  b764665a  45.280900   \n",
       "992   [-23.370056, -22.784344, -23.170521, -21.88824...  2c4668f9  34.002100   \n",
       "993   [-26.700037, -28.039034, -25.013737, -26.70015...  8b2054f8  38.014400   \n",
       "994   [-29.971981, -27.588308, -27.588366, -26.29926...  74725cf4  38.475500   \n",
       "995   [-24.515034, -25.854019, -29.375896, -27.09708...  364a544e  40.395800   \n",
       "996   [-25.714788, -24.691803, -27.859119, -25.99075...  d0a54ee0  36.691570   \n",
       "997   [-30.856735, -26.522608, -26.522659, -27.16640...  2d272de7  39.698200   \n",
       "998   [-31.110933, -32.270817, -31.111023, -30.58448...  308fc1fe  42.462500   \n",
       "999   [-24.525143, -24.293573, -23.633568, -21.56924...  17018107  35.294500   \n",
       "\n",
       "      is_iceberg  \n",
       "0              0  \n",
       "1              0  \n",
       "10             1  \n",
       "100            0  \n",
       "1000           0  \n",
       "1001           1  \n",
       "1002           0  \n",
       "1003           1  \n",
       "1004           1  \n",
       "1005           1  \n",
       "1006           0  \n",
       "1007           0  \n",
       "1008           0  \n",
       "1009           1  \n",
       "101            0  \n",
       "1010           1  \n",
       "1011           1  \n",
       "1012           1  \n",
       "1013           0  \n",
       "1014           1  \n",
       "1015           1  \n",
       "1016           0  \n",
       "1017           0  \n",
       "1018           1  \n",
       "1019           0  \n",
       "102            1  \n",
       "1020           1  \n",
       "1021           0  \n",
       "1022           1  \n",
       "1023           1  \n",
       "...          ...  \n",
       "972            0  \n",
       "973            0  \n",
       "974            1  \n",
       "975            1  \n",
       "976            0  \n",
       "977            1  \n",
       "978            0  \n",
       "979            1  \n",
       "98             1  \n",
       "980            1  \n",
       "981            1  \n",
       "982            1  \n",
       "983            1  \n",
       "984            0  \n",
       "985            1  \n",
       "986            0  \n",
       "987            1  \n",
       "988            1  \n",
       "989            1  \n",
       "99             1  \n",
       "990            1  \n",
       "991            1  \n",
       "992            1  \n",
       "993            0  \n",
       "994            1  \n",
       "995            1  \n",
       "996            0  \n",
       "997            0  \n",
       "998            0  \n",
       "999            1  \n",
       "\n",
       "[1604 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(im):\n",
    "    im = im - np.mean(im)\n",
    "    im = im / np.std(im)\n",
    "    return im\n",
    "\n",
    "def get_convolve(im1, im2):\n",
    "    im1 = im1 - np.mean(im1)\n",
    "    im2 = im2 - np.mean(im2)\n",
    "    im_conv = fftconvolve(im1, im2[::-1, ::-1], mode='same')\n",
    "    return normalize(im_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (1604, 75, 75, 2)\n",
      "X_inc_angle.shape (1604,)\n",
      "y.shape: (1604,)\n"
     ]
    }
   ],
   "source": [
    "X, y = [], []\n",
    "for im_band1, im_band2, label in zip(df['band_1'], df['band_2'], df['is_iceberg']):\n",
    "    im_band1 = np.array(im_band1).reshape(75, 75, 1)\n",
    "    im_band2 = np.array(im_band2).reshape(75, 75, 1)    \n",
    "    # Preprocess\n",
    "    # - Zero mean\n",
    "    im_band1 -= np.mean(im_band1)\n",
    "    im_band2 -= np.mean(im_band2)\n",
    "    # - Normalize\n",
    "    im_band1 /= np.std(im_band1)\n",
    "    im_band2 /= np.std(im_band2)    \n",
    "    im = np.concatenate([im_band1, im_band2], axis=2)\n",
    "#     im = np.concatenate([normalize(im_band1), normalize(im_band2), get_convolve(im_band1, im_band2)], axis=2)\n",
    "    X.append(im)\n",
    "    y.append(label)    \n",
    "X = np.array(X)\n",
    "X_inc_angle = np.array(df['inc_angle'])\n",
    "y = np.array(y)\n",
    "print 'X.shape:', X.shape\n",
    "print 'X_inc_angle.shape', X_inc_angle.shape\n",
    "print 'y.shape:', y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "MODEL_NUMBER = 1\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, random_state=RANDOM_SEED, shuffle=True)\n",
    "cv = list(skf.split(X, y > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1282, 75, 75, 2)\n",
      "X_train_inc_angle.shape: (1282,)\n",
      "y_train.shape: (1282,)\n",
      "X_val.shape: (322, 75, 75, 2)\n",
      "X_val_inc_angle.shape: (322,)\n",
      "y_val.shape: (322,)\n",
      "np.mean(y_train): 0.469578783151\n",
      "np.mean(y_val): 0.468944099379\n"
     ]
    }
   ],
   "source": [
    "train_i, val_i = cv[MODEL_NUMBER - 1]\n",
    "X_train, X_train_inc_angle, y_train = X[train_i], X_inc_angle[train_i], y[train_i]\n",
    "X_val, X_val_inc_angle, y_val = X[val_i], X_inc_angle[val_i], y[val_i]\n",
    "print 'X_train.shape:', X_train.shape\n",
    "print 'X_train_inc_angle.shape:', X_train_inc_angle.shape\n",
    "print 'y_train.shape:', y_train.shape\n",
    "print 'X_val.shape:', X_val.shape\n",
    "print 'X_val_inc_angle.shape:', X_val_inc_angle.shape\n",
    "print 'y_val.shape:', y_val.shape\n",
    "print 'np.mean(y_train):', np.mean(y_train)\n",
    "print 'np.mean(y_val):', np.mean(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1282, 75, 75, 2)\n",
      "X_train_inc_angle.shape: (1282,)\n",
      "y_train.shape: (1282,)\n",
      "X_val.shape: (322, 75, 75, 2)\n",
      "X_val_inc_angle.shape (322,)\n",
      "y_val.shape: (322,)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "X_train = np.concatenate([func(X_train) for func in aug_funcs], axis=0)\n",
    "y_train = np.concatenate([y_train] * len(aug_funcs))\n",
    "X_train_inc_angle = np.array(list(X_train_inc_angle) * len(aug_funcs))\n",
    "\n",
    "# Validation\n",
    "X_val = np.concatenate([func(X_val) for func in aug_funcs], axis=0)\n",
    "y_val = np.concatenate([y_val] * len(aug_funcs))\n",
    "X_val_inc_angle = np.array(list(X_val_inc_angle) * len(aug_funcs))\n",
    "\n",
    "# \n",
    "print 'X_train.shape:', X_train.shape\n",
    "print 'X_train_inc_angle.shape:', X_train_inc_angle.shape\n",
    "print 'y_train.shape:', y_train.shape\n",
    "print 'X_val.shape:', X_val.shape\n",
    "print 'X_val_inc_angle.shape', X_val_inc_angle.shape\n",
    "print 'y_val.shape:', y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape):\n",
    "    # Input\n",
    "    input_tensor = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Block 1\n",
    "    x = layers.Conv2D(32, kernel_size=(3, 3), activation='relu')(input_tensor)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Block 2\n",
    "    x = layers.Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)    \n",
    "    \n",
    "    # Block 3\n",
    "    x = layers.Conv2D(128, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Block 4\n",
    "    x = layers.Conv2D(256, kernel_size=(3, 3))(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # FC\n",
    "    x = layers.Flatten()(x)\n",
    "    # merge inc_angle\n",
    "    inc_angle = layers.Input(shape=(1,))\n",
    "    x = layers.concatenate([x, inc_angle])    \n",
    "    x = layers.Dense(32)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=[input_tensor, inc_angle], outputs=x)\n",
    "    \n",
    "    # Compile the model\n",
    "    loss = losses.binary_crossentropy\n",
    "    optimizer = optimizers.Adam()\n",
    "    metrics = ['accuracy']\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(input_shape=(75, 75, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1282 samples, validate on 322 samples\n",
      "Epoch 1/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.7185 - acc: 0.5609Epoch 00001: val_loss improved from inf to 0.64242, saving model to ./models/model20/model1.h5\n",
      "1282/1282 [==============================] - 2s 1ms/step - loss: 0.7183 - acc: 0.5616 - val_loss: 0.6424 - val_acc: 0.7236\n",
      "Epoch 2/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.5696 - acc: 0.6836Epoch 00002: val_loss improved from 0.64242 to 0.52007, saving model to ./models/model20/model1.h5\n",
      "1282/1282 [==============================] - 1s 634us/step - loss: 0.5698 - acc: 0.6833 - val_loss: 0.5201 - val_acc: 0.6770\n",
      "Epoch 3/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.5025 - acc: 0.7320Epoch 00003: val_loss improved from 0.52007 to 0.39766, saving model to ./models/model20/model1.h5\n",
      "1282/1282 [==============================] - 1s 636us/step - loss: 0.5021 - acc: 0.7324 - val_loss: 0.3977 - val_acc: 0.8199\n",
      "Epoch 4/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.3679 - acc: 0.8328Epoch 00004: val_loss improved from 0.39766 to 0.32424, saving model to ./models/model20/model1.h5\n",
      "1282/1282 [==============================] - 1s 636us/step - loss: 0.3674 - acc: 0.8331 - val_loss: 0.3242 - val_acc: 0.8509\n",
      "Epoch 5/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.3331 - acc: 0.8508Epoch 00005: val_loss improved from 0.32424 to 0.28423, saving model to ./models/model20/model1.h5\n",
      "1282/1282 [==============================] - 1s 638us/step - loss: 0.3329 - acc: 0.8510 - val_loss: 0.2842 - val_acc: 0.8882\n",
      "Epoch 6/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.3173 - acc: 0.8672Epoch 00006: val_loss did not improve\n",
      "1282/1282 [==============================] - 1s 624us/step - loss: 0.3170 - acc: 0.8674 - val_loss: 0.2956 - val_acc: 0.8820\n",
      "Epoch 7/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.2708 - acc: 0.8836Epoch 00007: val_loss did not improve\n",
      "1282/1282 [==============================] - 1s 621us/step - loss: 0.2722 - acc: 0.8830 - val_loss: 0.3740 - val_acc: 0.8323\n",
      "Epoch 8/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.8695Epoch 00008: val_loss did not improve\n",
      "1282/1282 [==============================] - 1s 636us/step - loss: 0.3177 - acc: 0.8690 - val_loss: 0.3104 - val_acc: 0.8602\n",
      "Epoch 9/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.2914 - acc: 0.8695Epoch 00009: val_loss did not improve\n",
      "\n",
      "Epoch 00009: reducing learning rate to 0.000330000015674.\n",
      "1282/1282 [==============================] - 1s 670us/step - loss: 0.2910 - acc: 0.8697 - val_loss: 0.2972 - val_acc: 0.8789\n",
      "Epoch 10/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.2154 - acc: 0.9062Epoch 00010: val_loss improved from 0.28423 to 0.26514, saving model to ./models/model20/model1.h5\n",
      "1282/1282 [==============================] - 1s 653us/step - loss: 0.2154 - acc: 0.9064 - val_loss: 0.2651 - val_acc: 0.8820\n",
      "Epoch 11/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.1837 - acc: 0.9266Epoch 00011: val_loss improved from 0.26514 to 0.25848, saving model to ./models/model20/model1.h5\n",
      "1282/1282 [==============================] - 1s 640us/step - loss: 0.1835 - acc: 0.9267 - val_loss: 0.2585 - val_acc: 0.8975\n",
      "Epoch 12/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9305Epoch 00012: val_loss did not improve\n",
      "1282/1282 [==============================] - 1s 618us/step - loss: 0.1817 - acc: 0.9306 - val_loss: 0.2650 - val_acc: 0.8944\n",
      "Epoch 13/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.1616 - acc: 0.9281Epoch 00013: val_loss did not improve\n",
      "1282/1282 [==============================] - 1s 609us/step - loss: 0.1626 - acc: 0.9275 - val_loss: 0.3730 - val_acc: 0.8727\n",
      "Epoch 14/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.1908 - acc: 0.9125Epoch 00014: val_loss did not improve\n",
      "1282/1282 [==============================] - 1s 641us/step - loss: 0.1908 - acc: 0.9126 - val_loss: 0.2603 - val_acc: 0.8975\n",
      "Epoch 15/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.1624 - acc: 0.9406Epoch 00015: val_loss did not improve\n",
      "\n",
      "Epoch 00015: reducing learning rate to 0.000108900003252.\n",
      "1282/1282 [==============================] - 1s 625us/step - loss: 0.1622 - acc: 0.9407 - val_loss: 0.2961 - val_acc: 0.9006\n",
      "Epoch 16/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9523Epoch 00016: val_loss did not improve\n",
      "1282/1282 [==============================] - 1s 627us/step - loss: 0.1266 - acc: 0.9524 - val_loss: 0.2764 - val_acc: 0.8913\n",
      "Epoch 17/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9469Epoch 00017: val_loss did not improve\n",
      "1282/1282 [==============================] - 1s 627us/step - loss: 0.1275 - acc: 0.9470 - val_loss: 0.2859 - val_acc: 0.8913\n",
      "Epoch 18/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9500Epoch 00018: val_loss did not improve\n",
      "\n",
      "Epoch 00018: reducing learning rate to 3.59369999205e-05.\n",
      "1282/1282 [==============================] - 1s 619us/step - loss: 0.1291 - acc: 0.9501 - val_loss: 0.2903 - val_acc: 0.8944\n",
      "Epoch 19/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9516Epoch 00019: val_loss did not improve\n",
      "1282/1282 [==============================] - 1s 611us/step - loss: 0.1223 - acc: 0.9516 - val_loss: 0.2823 - val_acc: 0.8913\n",
      "Epoch 20/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9547Epoch 00020: val_loss did not improve\n",
      "1282/1282 [==============================] - 1s 618us/step - loss: 0.1148 - acc: 0.9548 - val_loss: 0.2855 - val_acc: 0.8975\n",
      "Epoch 21/200\n",
      "1280/1282 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9531Epoch 00021: val_loss did not improve\n",
      "\n",
      "Epoch 00021: reducing learning rate to 1.18592095896e-05.\n",
      "1282/1282 [==============================] - 1s 616us/step - loss: 0.1157 - acc: 0.9532 - val_loss: 0.2883 - val_acc: 0.8975\n",
      "Epoch 00021: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbde5065650>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callbacks\n",
    "def get_lr(epoch):\n",
    "    lr = (np.random.rand() * 4e-2 + 1e-7)\n",
    "    lr = np.clip(lr, a_min=None, a_max=0.025)\n",
    "    print 'lr:', lr\n",
    "    return lr\n",
    "MODEL_PATH = './models/model20/model' + str(MODEL_NUMBER) + '.h5'\n",
    "m_q = 'val_loss'\n",
    "model_path = MODEL_PATH\n",
    "check_pt = callbacks.ModelCheckpoint(filepath=model_path, monitor=m_q, save_best_only=True, verbose=1)\n",
    "early_stop = callbacks.EarlyStopping(patience=10, monitor=m_q, verbose=1)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(patience=3, factor=0.33, monitor=m_q, verbose=1)\n",
    "schedule_lr = callbacks.LearningRateScheduler(get_lr)\n",
    "callback_list = [check_pt, early_stop, reduce_lr]\n",
    "\n",
    "model.fit([X_train, X_train_inc_angle], y_train, validation_data=([X_val, X_val_inc_angle], y_val), callbacks=callback_list, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape: (1604, 75, 75, 2)\n",
      "X_test_inc_angle.shape: (1604,)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "df = pd.read_json('./data/train.json')\n",
    "X_test, y_test = [], []\n",
    "for im_band1, im_band2 in zip(df['band_1'], df['band_2']):\n",
    "    im_band1 = np.array(im_band1).reshape(75, 75, 1)\n",
    "    im_band2 = np.array(im_band2).reshape(75, 75, 1)    \n",
    "    # Preprocess - zero mean\n",
    "    im_band1 -= np.mean(im_band1)\n",
    "    im_band2 -= np.mean(im_band2)\n",
    "    # Preprocess - normalize\n",
    "    im_band1 /= np.std(im_band1)\n",
    "    im_band2 /= np.std(im_band2)    \n",
    "    im = np.concatenate([im_band1, im_band2], axis=2)\n",
    "    X_test.append(im)    \n",
    "X_test = np.array(X_test)\n",
    "X_test_inc_angle = np.array(df['inc_angle'])\n",
    "print 'X_test.shape:', X_test.shape\n",
    "print 'X_test_inc_angle.shape:', X_test_inc_angle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "  32/1604 [..............................] - ETA: 2s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: na",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-60972c603673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# predict - tta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maug_funcs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0my_test_p\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_inc_angle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# y_test_p = y_test_p / (len(aug_funcs) * 5.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my_test_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_p\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_funcs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/can/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1746\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1748\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/can/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/can/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/can/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/can/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m/home/can/anaconda2/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: na"
     ]
    }
   ],
   "source": [
    "y_test_p = 0\n",
    "# weights = [0.25, 0.4 / 3, 0.35, 0.4 / 3, 0.4 / 3]\n",
    "# weights = [0.2, 0.18, 0.2, 0.2, 0.22]\n",
    "weights = [0.2] * 5\n",
    "for i, w in zip(range(5), weights):\n",
    "    print i\n",
    "    # Load the model\n",
    "    MODEL_PATH = './models/model20/model' + str(i + 1) + '.h5'\n",
    "    model = load_model(MODEL_PATH)\n",
    "    # predict - tta    \n",
    "    for func in aug_funcs:\n",
    "        y_test_p += model.predict([func(X_test), X_test_inc_angle], verbose=1).flatten() * w\n",
    "# y_test_p = y_test_p / (len(aug_funcs) * 5.0)\n",
    "y_test_p = y_test_p / (len(aug_funcs) * sum(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame()\n",
    "df_sub['id'] = df['id']\n",
    "df_sub['is_iceberg'] = y_test_p.flatten()\n",
    "df_sub.to_csv('./submissions/model20-train-predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
